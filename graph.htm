<!DOCTYPE html> <html> <body> 

        <iframe seamless style="width:1200px;height:620px;border:0" srcdoc="
        <script>
          function load() {
            document.getElementById(&quot;graph0.7386200175471126&quot;).pbtxt = 'node {\n  name: &quot;x&quot;\n  op: &quot;Placeholder&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: -1\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;y_/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;x&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;y_/strided_slice/stack&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;y_/strided_slice/stack_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;y_/strided_slice/stack_2&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;y_/strided_slice&quot;\n  op: &quot;StridedSlice&quot;\n  input: &quot;y_/Shape&quot;\n  input: &quot;y_/strided_slice/stack&quot;\n  input: &quot;y_/strided_slice/stack_1&quot;\n  input: &quot;y_/strided_slice/stack_2&quot;\n  attr {\n    key: &quot;Index&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;begin_mask&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;ellipsis_mask&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;end_mask&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;new_axis_mask&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;shrink_axis_mask&quot;\n    value {\n      i: 1\n    }\n  }\n}\nnode {\n  name: &quot;y_/stack/1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 2\n      }\n    }\n  }\n}\nnode {\n  name: &quot;y_/stack&quot;\n  op: &quot;Pack&quot;\n  input: &quot;y_/strided_slice&quot;\n  input: &quot;y_/stack/1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;axis&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;y_/Fill/value&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;y_/Fill&quot;\n  op: &quot;Fill&quot;\n  input: &quot;y_/stack&quot;\n  input: &quot;y_/Fill/value&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/weights/Initializer/random_uniform/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\002\\000\\000\\000\\002\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/weights/Initializer/random_uniform/min&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: -1.2247449159622192\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/weights/Initializer/random_uniform/max&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.2247449159622192\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/weights/Initializer/random_uniform/RandomUniform&quot;\n  op: &quot;RandomUniform&quot;\n  input: &quot;qy/layer1/weights/Initializer/random_uniform/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/weights/Initializer/random_uniform/sub&quot;\n  op: &quot;Sub&quot;\n  input: &quot;qy/layer1/weights/Initializer/random_uniform/max&quot;\n  input: &quot;qy/layer1/weights/Initializer/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/weights/Initializer/random_uniform/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;qy/layer1/weights/Initializer/random_uniform/RandomUniform&quot;\n  input: &quot;qy/layer1/weights/Initializer/random_uniform/sub&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/weights/Initializer/random_uniform&quot;\n  op: &quot;Add&quot;\n  input: &quot;qy/layer1/weights/Initializer/random_uniform/mul&quot;\n  input: &quot;qy/layer1/weights/Initializer/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/weights&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/weights/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qy/layer1/weights&quot;\n  input: &quot;qy/layer1/weights/Initializer/random_uniform&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/weights/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qy/layer1/weights&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/biases/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/biases&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/biases/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qy/layer1/biases&quot;\n  input: &quot;qy/layer1/biases/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/biases/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qy/layer1/biases&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;x&quot;\n  input: &quot;qy/layer1/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;qy/layer1/MatMul&quot;\n  input: &quot;qy/layer1/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/Relu&quot;\n  op: &quot;Relu&quot;\n  input: &quot;qy/layer1/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/weights/Initializer/random_uniform/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\002\\000\\000\\000\\002\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/weights/Initializer/random_uniform/min&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: -1.2247449159622192\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/weights/Initializer/random_uniform/max&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.2247449159622192\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/weights/Initializer/random_uniform/RandomUniform&quot;\n  op: &quot;RandomUniform&quot;\n  input: &quot;qy/logit/weights/Initializer/random_uniform/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/weights/Initializer/random_uniform/sub&quot;\n  op: &quot;Sub&quot;\n  input: &quot;qy/logit/weights/Initializer/random_uniform/max&quot;\n  input: &quot;qy/logit/weights/Initializer/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/weights/Initializer/random_uniform/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;qy/logit/weights/Initializer/random_uniform/RandomUniform&quot;\n  input: &quot;qy/logit/weights/Initializer/random_uniform/sub&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/weights/Initializer/random_uniform&quot;\n  op: &quot;Add&quot;\n  input: &quot;qy/logit/weights/Initializer/random_uniform/mul&quot;\n  input: &quot;qy/logit/weights/Initializer/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/weights&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/weights/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qy/logit/weights&quot;\n  input: &quot;qy/logit/weights/Initializer/random_uniform&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/weights/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qy/logit/weights&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/biases/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/biases&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/biases/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qy/logit/biases&quot;\n  input: &quot;qy/logit/biases/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/biases/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qy/logit/biases&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;qy/layer1/Relu&quot;\n  input: &quot;qy/logit/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;qy/logit/MatMul&quot;\n  input: &quot;qy/logit/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/Relu&quot;\n  op: &quot;Relu&quot;\n  input: &quot;qy/logit/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;qy/prob&quot;\n  op: &quot;Softmax&quot;\n  input: &quot;qy/logit/Relu&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/hot_at_0&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\000\\000\\200?\\000\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/Add&quot;\n  op: &quot;Add&quot;\n  input: &quot;y_/Fill&quot;\n  input: &quot;graphs/hot_at0/hot_at_0&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/qz/xy/concat/axis&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/qz/xy/concat&quot;\n  op: &quot;ConcatV2&quot;\n  input: &quot;x&quot;\n  input: &quot;graphs/hot_at0/Add&quot;\n  input: &quot;graphs/hot_at0/qz/xy/concat/axis&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/weights/Initializer/random_uniform/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\004\\000\\000\\000\\004\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/weights/Initializer/random_uniform/min&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: -0.8660253882408142\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/weights/Initializer/random_uniform/max&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.8660253882408142\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/weights/Initializer/random_uniform/RandomUniform&quot;\n  op: &quot;RandomUniform&quot;\n  input: &quot;qz/layer1/weights/Initializer/random_uniform/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/weights/Initializer/random_uniform/sub&quot;\n  op: &quot;Sub&quot;\n  input: &quot;qz/layer1/weights/Initializer/random_uniform/max&quot;\n  input: &quot;qz/layer1/weights/Initializer/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/weights/Initializer/random_uniform/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;qz/layer1/weights/Initializer/random_uniform/RandomUniform&quot;\n  input: &quot;qz/layer1/weights/Initializer/random_uniform/sub&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/weights/Initializer/random_uniform&quot;\n  op: &quot;Add&quot;\n  input: &quot;qz/layer1/weights/Initializer/random_uniform/mul&quot;\n  input: &quot;qz/layer1/weights/Initializer/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/weights&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 4\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/weights/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qz/layer1/weights&quot;\n  input: &quot;qz/layer1/weights/Initializer/random_uniform&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/weights/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qz/layer1/weights&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/biases/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 4\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/biases&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/biases/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qz/layer1/biases&quot;\n  input: &quot;qz/layer1/biases/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/biases/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qz/layer1/biases&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/qz/layer1/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at0/qz/xy/concat&quot;\n  input: &quot;qz/layer1/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/qz/layer1/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;graphs/hot_at0/qz/layer1/MatMul&quot;\n  input: &quot;qz/layer1/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/qz/layer1/Relu&quot;\n  op: &quot;Relu&quot;\n  input: &quot;graphs/hot_at0/qz/layer1/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/weights/Initializer/random_uniform/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\004\\000\\000\\000\\002\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/weights/Initializer/random_uniform/min&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: -1.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/weights/Initializer/random_uniform/max&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/weights/Initializer/random_uniform/RandomUniform&quot;\n  op: &quot;RandomUniform&quot;\n  input: &quot;qz/zm/weights/Initializer/random_uniform/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/weights/Initializer/random_uniform/sub&quot;\n  op: &quot;Sub&quot;\n  input: &quot;qz/zm/weights/Initializer/random_uniform/max&quot;\n  input: &quot;qz/zm/weights/Initializer/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/weights/Initializer/random_uniform/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;qz/zm/weights/Initializer/random_uniform/RandomUniform&quot;\n  input: &quot;qz/zm/weights/Initializer/random_uniform/sub&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/weights/Initializer/random_uniform&quot;\n  op: &quot;Add&quot;\n  input: &quot;qz/zm/weights/Initializer/random_uniform/mul&quot;\n  input: &quot;qz/zm/weights/Initializer/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/weights&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/weights/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qz/zm/weights&quot;\n  input: &quot;qz/zm/weights/Initializer/random_uniform&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/weights/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qz/zm/weights&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/biases/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/biases&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/biases/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qz/zm/biases&quot;\n  input: &quot;qz/zm/biases/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/biases/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qz/zm/biases&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/qz/zm/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at0/qz/layer1/Relu&quot;\n  input: &quot;qz/zm/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/qz/zm/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;graphs/hot_at0/qz/zm/MatMul&quot;\n  input: &quot;qz/zm/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/weights/Initializer/random_uniform/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\004\\000\\000\\000\\002\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/weights/Initializer/random_uniform/min&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: -1.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/weights/Initializer/random_uniform/max&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/weights/Initializer/random_uniform/RandomUniform&quot;\n  op: &quot;RandomUniform&quot;\n  input: &quot;qz/zv/weights/Initializer/random_uniform/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/weights/Initializer/random_uniform/sub&quot;\n  op: &quot;Sub&quot;\n  input: &quot;qz/zv/weights/Initializer/random_uniform/max&quot;\n  input: &quot;qz/zv/weights/Initializer/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/weights/Initializer/random_uniform/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;qz/zv/weights/Initializer/random_uniform/RandomUniform&quot;\n  input: &quot;qz/zv/weights/Initializer/random_uniform/sub&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/weights/Initializer/random_uniform&quot;\n  op: &quot;Add&quot;\n  input: &quot;qz/zv/weights/Initializer/random_uniform/mul&quot;\n  input: &quot;qz/zv/weights/Initializer/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/weights&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/weights/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qz/zv/weights&quot;\n  input: &quot;qz/zv/weights/Initializer/random_uniform&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/weights/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qz/zv/weights&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/biases/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/biases&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/biases/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qz/zv/biases&quot;\n  input: &quot;qz/zv/biases/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/biases/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qz/zv/biases&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/qz/zv/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at0/qz/layer1/Relu&quot;\n  input: &quot;qz/zv/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/qz/zv/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;graphs/hot_at0/qz/zv/MatMul&quot;\n  input: &quot;qz/zv/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/qz/zv/Softplus&quot;\n  op: &quot;Softplus&quot;\n  input: &quot;graphs/hot_at0/qz/zv/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/qz/z/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at0/qz/zm/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/qz/z/Sqrt&quot;\n  op: &quot;Sqrt&quot;\n  input: &quot;graphs/hot_at0/qz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/qz/z/random_normal/RandomStandardNormal&quot;\n  op: &quot;RandomStandardNormal&quot;\n  input: &quot;graphs/hot_at0/qz/z/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/qz/z/random_normal/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;graphs/hot_at0/qz/z/random_normal/RandomStandardNormal&quot;\n  input: &quot;graphs/hot_at0/qz/z/Sqrt&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/qz/z/random_normal&quot;\n  op: &quot;Add&quot;\n  input: &quot;graphs/hot_at0/qz/z/random_normal/mul&quot;\n  input: &quot;graphs/hot_at0/qz/zm/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/qz/z_sample&quot;\n  op: &quot;Identity&quot;\n  input: &quot;graphs/hot_at0/qz/z/random_normal&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/weights/Initializer/random_uniform/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\002\\000\\000\\000\\002\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/weights/Initializer/random_uniform/min&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: -1.2247449159622192\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/weights/Initializer/random_uniform/max&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.2247449159622192\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/weights/Initializer/random_uniform/RandomUniform&quot;\n  op: &quot;RandomUniform&quot;\n  input: &quot;pz/zm/weights/Initializer/random_uniform/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/weights/Initializer/random_uniform/sub&quot;\n  op: &quot;Sub&quot;\n  input: &quot;pz/zm/weights/Initializer/random_uniform/max&quot;\n  input: &quot;pz/zm/weights/Initializer/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/weights/Initializer/random_uniform/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;pz/zm/weights/Initializer/random_uniform/RandomUniform&quot;\n  input: &quot;pz/zm/weights/Initializer/random_uniform/sub&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/weights/Initializer/random_uniform&quot;\n  op: &quot;Add&quot;\n  input: &quot;pz/zm/weights/Initializer/random_uniform/mul&quot;\n  input: &quot;pz/zm/weights/Initializer/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/weights&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/weights/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;pz/zm/weights&quot;\n  input: &quot;pz/zm/weights/Initializer/random_uniform&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/weights/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;pz/zm/weights&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/biases/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/biases&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/biases/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;pz/zm/biases&quot;\n  input: &quot;pz/zm/biases/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/biases/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;pz/zm/biases&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/pz/zm/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at0/Add&quot;\n  input: &quot;pz/zm/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/pz/zm/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;graphs/hot_at0/pz/zm/MatMul&quot;\n  input: &quot;pz/zm/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/weights/Initializer/random_uniform/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\002\\000\\000\\000\\002\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/weights/Initializer/random_uniform/min&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: -1.2247449159622192\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/weights/Initializer/random_uniform/max&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.2247449159622192\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/weights/Initializer/random_uniform/RandomUniform&quot;\n  op: &quot;RandomUniform&quot;\n  input: &quot;pz/zv/weights/Initializer/random_uniform/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/weights/Initializer/random_uniform/sub&quot;\n  op: &quot;Sub&quot;\n  input: &quot;pz/zv/weights/Initializer/random_uniform/max&quot;\n  input: &quot;pz/zv/weights/Initializer/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/weights/Initializer/random_uniform/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;pz/zv/weights/Initializer/random_uniform/RandomUniform&quot;\n  input: &quot;pz/zv/weights/Initializer/random_uniform/sub&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/weights/Initializer/random_uniform&quot;\n  op: &quot;Add&quot;\n  input: &quot;pz/zv/weights/Initializer/random_uniform/mul&quot;\n  input: &quot;pz/zv/weights/Initializer/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/weights&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/weights/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;pz/zv/weights&quot;\n  input: &quot;pz/zv/weights/Initializer/random_uniform&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/weights/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;pz/zv/weights&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/biases/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/biases&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/biases/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;pz/zv/biases&quot;\n  input: &quot;pz/zv/biases/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/biases/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;pz/zv/biases&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/pz/zv/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at0/Add&quot;\n  input: &quot;pz/zv/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/pz/zv/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;graphs/hot_at0/pz/zv/MatMul&quot;\n  input: &quot;pz/zv/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/pz/zv/Softplus&quot;\n  op: &quot;Softplus&quot;\n  input: &quot;graphs/hot_at0/pz/zv/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/weights/Initializer/random_uniform/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\002\\000\\000\\000\\002\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/weights/Initializer/random_uniform/min&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: -1.2247449159622192\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/weights/Initializer/random_uniform/max&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.2247449159622192\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/weights/Initializer/random_uniform/RandomUniform&quot;\n  op: &quot;RandomUniform&quot;\n  input: &quot;px/layer1/weights/Initializer/random_uniform/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/weights/Initializer/random_uniform/sub&quot;\n  op: &quot;Sub&quot;\n  input: &quot;px/layer1/weights/Initializer/random_uniform/max&quot;\n  input: &quot;px/layer1/weights/Initializer/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/weights/Initializer/random_uniform/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;px/layer1/weights/Initializer/random_uniform/RandomUniform&quot;\n  input: &quot;px/layer1/weights/Initializer/random_uniform/sub&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/weights/Initializer/random_uniform&quot;\n  op: &quot;Add&quot;\n  input: &quot;px/layer1/weights/Initializer/random_uniform/mul&quot;\n  input: &quot;px/layer1/weights/Initializer/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/weights&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/weights/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;px/layer1/weights&quot;\n  input: &quot;px/layer1/weights/Initializer/random_uniform&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/weights/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;px/layer1/weights&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/biases/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/biases&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/biases/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;px/layer1/biases&quot;\n  input: &quot;px/layer1/biases/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/biases/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;px/layer1/biases&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/px/layer1/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at0/qz/z_sample&quot;\n  input: &quot;px/layer1/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/px/layer1/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;graphs/hot_at0/px/layer1/MatMul&quot;\n  input: &quot;px/layer1/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/px/layer1/Relu&quot;\n  op: &quot;Relu&quot;\n  input: &quot;graphs/hot_at0/px/layer1/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;px/output/weights/Initializer/random_uniform/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\002\\000\\000\\000\\002\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/output/weights/Initializer/random_uniform/min&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: -1.2247449159622192\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/output/weights/Initializer/random_uniform/max&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.2247449159622192\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/output/weights/Initializer/random_uniform/RandomUniform&quot;\n  op: &quot;RandomUniform&quot;\n  input: &quot;px/output/weights/Initializer/random_uniform/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;px/output/weights/Initializer/random_uniform/sub&quot;\n  op: &quot;Sub&quot;\n  input: &quot;px/output/weights/Initializer/random_uniform/max&quot;\n  input: &quot;px/output/weights/Initializer/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/output/weights/Initializer/random_uniform/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;px/output/weights/Initializer/random_uniform/RandomUniform&quot;\n  input: &quot;px/output/weights/Initializer/random_uniform/sub&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/output/weights/Initializer/random_uniform&quot;\n  op: &quot;Add&quot;\n  input: &quot;px/output/weights/Initializer/random_uniform/mul&quot;\n  input: &quot;px/output/weights/Initializer/random_uniform/min&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/output/weights&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;px/output/weights/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;px/output/weights&quot;\n  input: &quot;px/output/weights/Initializer/random_uniform&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;px/output/weights/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;px/output/weights&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/output/biases/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/output/biases&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;px/output/biases/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;px/output/biases&quot;\n  input: &quot;px/output/biases/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;px/output/biases/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;px/output/biases&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/px/output/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at0/px/layer1/Relu&quot;\n  input: &quot;px/output/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at0/px/output/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;graphs/hot_at0/px/output/MatMul&quot;\n  input: &quot;px/output/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/hot_at_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\000\\000\\000\\000\\000\\000\\200?&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/Add&quot;\n  op: &quot;Add&quot;\n  input: &quot;y_/Fill&quot;\n  input: &quot;graphs/hot_at1/hot_at_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/qz/xy/concat/axis&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/qz/xy/concat&quot;\n  op: &quot;ConcatV2&quot;\n  input: &quot;x&quot;\n  input: &quot;graphs/hot_at1/Add&quot;\n  input: &quot;graphs/hot_at1/qz/xy/concat/axis&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/qz/layer1/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at1/qz/xy/concat&quot;\n  input: &quot;qz/layer1/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/qz/layer1/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;graphs/hot_at1/qz/layer1/MatMul&quot;\n  input: &quot;qz/layer1/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/qz/layer1/Relu&quot;\n  op: &quot;Relu&quot;\n  input: &quot;graphs/hot_at1/qz/layer1/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/qz/zm/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at1/qz/layer1/Relu&quot;\n  input: &quot;qz/zm/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/qz/zm/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;graphs/hot_at1/qz/zm/MatMul&quot;\n  input: &quot;qz/zm/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/qz/zv/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at1/qz/layer1/Relu&quot;\n  input: &quot;qz/zv/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/qz/zv/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;graphs/hot_at1/qz/zv/MatMul&quot;\n  input: &quot;qz/zv/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/qz/zv/Softplus&quot;\n  op: &quot;Softplus&quot;\n  input: &quot;graphs/hot_at1/qz/zv/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/qz/z/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at1/qz/zm/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/qz/z/Sqrt&quot;\n  op: &quot;Sqrt&quot;\n  input: &quot;graphs/hot_at1/qz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/qz/z/random_normal/RandomStandardNormal&quot;\n  op: &quot;RandomStandardNormal&quot;\n  input: &quot;graphs/hot_at1/qz/z/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;seed&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;seed2&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/qz/z/random_normal/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;graphs/hot_at1/qz/z/random_normal/RandomStandardNormal&quot;\n  input: &quot;graphs/hot_at1/qz/z/Sqrt&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/qz/z/random_normal&quot;\n  op: &quot;Add&quot;\n  input: &quot;graphs/hot_at1/qz/z/random_normal/mul&quot;\n  input: &quot;graphs/hot_at1/qz/zm/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/qz/z_sample&quot;\n  op: &quot;Identity&quot;\n  input: &quot;graphs/hot_at1/qz/z/random_normal&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/pz/zm/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at1/Add&quot;\n  input: &quot;pz/zm/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/pz/zm/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;graphs/hot_at1/pz/zm/MatMul&quot;\n  input: &quot;pz/zm/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/pz/zv/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at1/Add&quot;\n  input: &quot;pz/zv/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/pz/zv/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;graphs/hot_at1/pz/zv/MatMul&quot;\n  input: &quot;pz/zv/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/pz/zv/Softplus&quot;\n  op: &quot;Softplus&quot;\n  input: &quot;graphs/hot_at1/pz/zv/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/px/layer1/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at1/qz/z_sample&quot;\n  input: &quot;px/layer1/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/px/layer1/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;graphs/hot_at1/px/layer1/MatMul&quot;\n  input: &quot;px/layer1/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/px/layer1/Relu&quot;\n  op: &quot;Relu&quot;\n  input: &quot;graphs/hot_at1/px/layer1/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/px/output/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at1/px/layer1/Relu&quot;\n  input: &quot;px/output/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;graphs/hot_at1/px/output/BiasAdd&quot;\n  op: &quot;BiasAdd&quot;\n  input: &quot;graphs/hot_at1/px/output/MatMul&quot;\n  input: &quot;px/output/biases/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Rank&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 2\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;qy/logit/Relu&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Rank_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 2\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;qy/logit/Relu&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Sub/y&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Sub&quot;\n  op: &quot;Sub&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Rank_1&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Sub/y&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Slice/begin&quot;\n  op: &quot;Pack&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Sub&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 1\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;axis&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Slice/size&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Slice&quot;\n  op: &quot;Slice&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Shape_1&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Slice/begin&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Slice/size&quot;\n  attr {\n    key: &quot;Index&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/concat/values_0&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: -1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/concat/axis&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/concat&quot;\n  op: &quot;ConcatV2&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/concat/values_0&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Slice&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/concat/axis&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;qy/logit/Relu&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/concat&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Rank_2&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 2\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Shape_2&quot;\n  op: &quot;Shape&quot;\n  input: &quot;qy/prob&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Sub_1/y&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Sub_1&quot;\n  op: &quot;Sub&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Rank_2&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Sub_1/y&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Slice_1/begin&quot;\n  op: &quot;Pack&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Sub_1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 1\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;axis&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Slice_1/size&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Slice_1&quot;\n  op: &quot;Slice&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Shape_2&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Slice_1/begin&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Slice_1/size&quot;\n  attr {\n    key: &quot;Index&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/concat_1/values_0&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: -1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/concat_1/axis&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/concat_1&quot;\n  op: &quot;ConcatV2&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/concat_1/values_0&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Slice_1&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/concat_1/axis&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;qy/prob&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/concat_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits&quot;\n  op: &quot;SoftmaxCrossEntropyWithLogits&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Sub_2/y&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Sub_2&quot;\n  op: &quot;Sub&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Rank&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Sub_2/y&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Slice_2/begin&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Slice_2/size&quot;\n  op: &quot;Pack&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Sub_2&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 1\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;axis&quot;\n    value {\n      i: 0\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Slice_2&quot;\n  op: &quot;Slice&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Shape&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Slice_2/begin&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Slice_2/size&quot;\n  attr {\n    key: &quot;Index&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape_2&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Slice_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;loss/neg_entropy/Neg&quot;\n  op: &quot;Neg&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/SquaredDifference&quot;\n  op: &quot;SquaredDifference&quot;\n  input: &quot;graphs/hot_at0/px/output/BiasAdd&quot;\n  input: &quot;x&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/assert_broadcastable/weights&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/assert_broadcastable/weights/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/assert_broadcastable/weights/rank&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/assert_broadcastable/values/shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/SquaredDifference&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/assert_broadcastable/values/rank&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 2\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  op: &quot;NoOp&quot;\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/ToFloat_3/x&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/Mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/SquaredDifference&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/ToFloat_3/x&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/Const&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\000\\000\\000\\000\\001\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/Mul&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/Const&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/num_present/Equal/y&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/num_present/Equal&quot;\n  op: &quot;Equal&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/ToFloat_3/x&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/num_present/Equal/y&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/num_present/zeros_like&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/num_present/ones_like/Shape&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/num_present/ones_like/Const&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/num_present/ones_like&quot;\n  op: &quot;Fill&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/num_present/ones_like/Shape&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/num_present/ones_like/Const&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/num_present/Select&quot;\n  op: &quot;Select&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/num_present/Equal&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/num_present/zeros_like&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/num_present/ones_like&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/num_present/broadcast_weights/assert_broadcastable/weights/shape&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/num_present/broadcast_weights/assert_broadcastable/weights/rank&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/num_present/broadcast_weights/assert_broadcastable/values/shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/SquaredDifference&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/num_present/broadcast_weights/assert_broadcastable/values/rank&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 2\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/num_present/broadcast_weights/ones_like/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/SquaredDifference&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/num_present/broadcast_weights/ones_like/Const&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/num_present/broadcast_weights/ones_like&quot;\n  op: &quot;Fill&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/num_present/broadcast_weights/ones_like/Shape&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/num_present/broadcast_weights/ones_like/Const&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/num_present/broadcast_weights&quot;\n  op: &quot;Mul&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/num_present/Select&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/num_present/broadcast_weights/ones_like&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/num_present/Const&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\000\\000\\000\\000\\001\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/num_present&quot;\n  op: &quot;Sum&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/num_present/broadcast_weights&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/num_present/Const&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/Const_1&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/Sum&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/Const_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/Greater/y&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/Greater&quot;\n  op: &quot;Greater&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/num_present&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/Greater/y&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/Equal/y&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/Equal&quot;\n  op: &quot;Equal&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/num_present&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/Equal/y&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/ones_like/Shape&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/ones_like/Const&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/ones_like&quot;\n  op: &quot;Fill&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/ones_like/Shape&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/ones_like/Const&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/Select&quot;\n  op: &quot;Select&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/Equal&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/ones_like&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/num_present&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/div&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/Sum_1&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/Select&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/zeros_like&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at0/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mean_squared_error/value&quot;\n  op: &quot;Select&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/Greater&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/div&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/zeros_like&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/Log/x&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 6.2831854820251465\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/Log&quot;\n  op: &quot;Log&quot;\n  input: &quot;loss/loss_at0/Log/x&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/Log_1&quot;\n  op: &quot;Log&quot;\n  input: &quot;graphs/hot_at0/qz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/add&quot;\n  op: &quot;Add&quot;\n  input: &quot;loss/loss_at0/Log&quot;\n  input: &quot;loss/loss_at0/Log_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/sub&quot;\n  op: &quot;Sub&quot;\n  input: &quot;graphs/hot_at0/qz/z_sample&quot;\n  input: &quot;graphs/hot_at0/qz/zm/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/Square&quot;\n  op: &quot;Square&quot;\n  input: &quot;loss/loss_at0/sub&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/truediv&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;loss/loss_at0/Square&quot;\n  input: &quot;graphs/hot_at0/qz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/add_1&quot;\n  op: &quot;Add&quot;\n  input: &quot;loss/loss_at0/add&quot;\n  input: &quot;loss/loss_at0/truediv&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/Sum/reduction_indices&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: -1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;loss/loss_at0/add_1&quot;\n  input: &quot;loss/loss_at0/Sum/reduction_indices&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mul/x&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: -0.5\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;loss/loss_at0/mul/x&quot;\n  input: &quot;loss/loss_at0/Sum&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/Log_2/x&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 6.2831854820251465\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/Log_2&quot;\n  op: &quot;Log&quot;\n  input: &quot;loss/loss_at0/Log_2/x&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/Log_3&quot;\n  op: &quot;Log&quot;\n  input: &quot;graphs/hot_at0/pz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/add_2&quot;\n  op: &quot;Add&quot;\n  input: &quot;loss/loss_at0/Log_2&quot;\n  input: &quot;loss/loss_at0/Log_3&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/sub_1&quot;\n  op: &quot;Sub&quot;\n  input: &quot;graphs/hot_at0/qz/z_sample&quot;\n  input: &quot;graphs/hot_at0/pz/zm/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/Square_1&quot;\n  op: &quot;Square&quot;\n  input: &quot;loss/loss_at0/sub_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/truediv_1&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;loss/loss_at0/Square_1&quot;\n  input: &quot;graphs/hot_at0/pz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/add_3&quot;\n  op: &quot;Add&quot;\n  input: &quot;loss/loss_at0/add_2&quot;\n  input: &quot;loss/loss_at0/truediv_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/Sum_1/reduction_indices&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: -1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;loss/loss_at0/add_3&quot;\n  input: &quot;loss/loss_at0/Sum_1/reduction_indices&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mul_1/x&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: -0.5\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;loss/loss_at0/mul_1/x&quot;\n  input: &quot;loss/loss_at0/Sum_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/sub_2&quot;\n  op: &quot;Sub&quot;\n  input: &quot;loss/loss_at0/mul&quot;\n  input: &quot;loss/loss_at0/mul_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/add_4&quot;\n  op: &quot;Add&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/value&quot;\n  input: &quot;loss/loss_at0/sub_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/sub_3/y&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: -2.3025851249694824\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at0/sub_3&quot;\n  op: &quot;Sub&quot;\n  input: &quot;loss/loss_at0/add_4&quot;\n  input: &quot;loss/loss_at0/sub_3/y&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/SquaredDifference&quot;\n  op: &quot;SquaredDifference&quot;\n  input: &quot;graphs/hot_at1/px/output/BiasAdd&quot;\n  input: &quot;x&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/assert_broadcastable/weights&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/assert_broadcastable/weights/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/assert_broadcastable/weights/rank&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/assert_broadcastable/values/shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/SquaredDifference&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/assert_broadcastable/values/rank&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 2\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  op: &quot;NoOp&quot;\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/ToFloat_3/x&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/Mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/SquaredDifference&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/ToFloat_3/x&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/Const&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\000\\000\\000\\000\\001\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/Mul&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/Const&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/num_present/Equal/y&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/num_present/Equal&quot;\n  op: &quot;Equal&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/ToFloat_3/x&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/num_present/Equal/y&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/num_present/zeros_like&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/num_present/ones_like/Shape&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/num_present/ones_like/Const&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/num_present/ones_like&quot;\n  op: &quot;Fill&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/num_present/ones_like/Shape&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/num_present/ones_like/Const&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/num_present/Select&quot;\n  op: &quot;Select&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/num_present/Equal&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/num_present/zeros_like&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/num_present/ones_like&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/num_present/broadcast_weights/assert_broadcastable/weights/shape&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/num_present/broadcast_weights/assert_broadcastable/weights/rank&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/num_present/broadcast_weights/assert_broadcastable/values/shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/SquaredDifference&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/num_present/broadcast_weights/assert_broadcastable/values/rank&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 2\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/num_present/broadcast_weights/ones_like/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/SquaredDifference&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/num_present/broadcast_weights/ones_like/Const&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/num_present/broadcast_weights/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/num_present/broadcast_weights/ones_like&quot;\n  op: &quot;Fill&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/num_present/broadcast_weights/ones_like/Shape&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/num_present/broadcast_weights/ones_like/Const&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/num_present/broadcast_weights&quot;\n  op: &quot;Mul&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/num_present/Select&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/num_present/broadcast_weights/ones_like&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/num_present/Const&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\000\\000\\000\\000\\001\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/num_present&quot;\n  op: &quot;Sum&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/num_present/broadcast_weights&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/num_present/Const&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/Const_1&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/Sum&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/Const_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/Greater/y&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/Greater&quot;\n  op: &quot;Greater&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/num_present&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/Greater/y&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/Equal/y&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/Equal&quot;\n  op: &quot;Equal&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/num_present&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/Equal/y&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/ones_like/Shape&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/ones_like/Const&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/ones_like&quot;\n  op: &quot;Fill&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/ones_like/Shape&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/ones_like/Const&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/Select&quot;\n  op: &quot;Select&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/Equal&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/ones_like&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/num_present&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/div&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/Sum_1&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/Select&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/zeros_like&quot;\n  op: &quot;Const&quot;\n  input: &quot;^loss/loss_at1/mean_squared_error/assert_broadcastable/static_scalar_check_success&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mean_squared_error/value&quot;\n  op: &quot;Select&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/Greater&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/div&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/zeros_like&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/Log/x&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 6.2831854820251465\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/Log&quot;\n  op: &quot;Log&quot;\n  input: &quot;loss/loss_at1/Log/x&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/Log_1&quot;\n  op: &quot;Log&quot;\n  input: &quot;graphs/hot_at1/qz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/add&quot;\n  op: &quot;Add&quot;\n  input: &quot;loss/loss_at1/Log&quot;\n  input: &quot;loss/loss_at1/Log_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/sub&quot;\n  op: &quot;Sub&quot;\n  input: &quot;graphs/hot_at1/qz/z_sample&quot;\n  input: &quot;graphs/hot_at1/qz/zm/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/Square&quot;\n  op: &quot;Square&quot;\n  input: &quot;loss/loss_at1/sub&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/truediv&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;loss/loss_at1/Square&quot;\n  input: &quot;graphs/hot_at1/qz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/add_1&quot;\n  op: &quot;Add&quot;\n  input: &quot;loss/loss_at1/add&quot;\n  input: &quot;loss/loss_at1/truediv&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/Sum/reduction_indices&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: -1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;loss/loss_at1/add_1&quot;\n  input: &quot;loss/loss_at1/Sum/reduction_indices&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mul/x&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: -0.5\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;loss/loss_at1/mul/x&quot;\n  input: &quot;loss/loss_at1/Sum&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/Log_2/x&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 6.2831854820251465\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/Log_2&quot;\n  op: &quot;Log&quot;\n  input: &quot;loss/loss_at1/Log_2/x&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/Log_3&quot;\n  op: &quot;Log&quot;\n  input: &quot;graphs/hot_at1/pz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/add_2&quot;\n  op: &quot;Add&quot;\n  input: &quot;loss/loss_at1/Log_2&quot;\n  input: &quot;loss/loss_at1/Log_3&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/sub_1&quot;\n  op: &quot;Sub&quot;\n  input: &quot;graphs/hot_at1/qz/z_sample&quot;\n  input: &quot;graphs/hot_at1/pz/zm/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/Square_1&quot;\n  op: &quot;Square&quot;\n  input: &quot;loss/loss_at1/sub_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/truediv_1&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;loss/loss_at1/Square_1&quot;\n  input: &quot;graphs/hot_at1/pz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/add_3&quot;\n  op: &quot;Add&quot;\n  input: &quot;loss/loss_at1/add_2&quot;\n  input: &quot;loss/loss_at1/truediv_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/Sum_1/reduction_indices&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: -1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;loss/loss_at1/add_3&quot;\n  input: &quot;loss/loss_at1/Sum_1/reduction_indices&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mul_1/x&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: -0.5\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;loss/loss_at1/mul_1/x&quot;\n  input: &quot;loss/loss_at1/Sum_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/sub_2&quot;\n  op: &quot;Sub&quot;\n  input: &quot;loss/loss_at1/mul&quot;\n  input: &quot;loss/loss_at1/mul_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/add_4&quot;\n  op: &quot;Add&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/value&quot;\n  input: &quot;loss/loss_at1/sub_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/sub_3/y&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: -2.3025851249694824\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/loss_at1/sub_3&quot;\n  op: &quot;Sub&quot;\n  input: &quot;loss/loss_at1/add_4&quot;\n  input: &quot;loss/loss_at1/sub_3/y&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/final_loss/strided_slice/stack&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\000\\000\\000\\000\\000\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/final_loss/strided_slice/stack_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\000\\000\\000\\000\\001\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/final_loss/strided_slice/stack_2&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\001\\000\\000\\000\\001\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/final_loss/strided_slice&quot;\n  op: &quot;StridedSlice&quot;\n  input: &quot;qy/prob&quot;\n  input: &quot;loss/final_loss/strided_slice/stack&quot;\n  input: &quot;loss/final_loss/strided_slice/stack_1&quot;\n  input: &quot;loss/final_loss/strided_slice/stack_2&quot;\n  attr {\n    key: &quot;Index&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;begin_mask&quot;\n    value {\n      i: 1\n    }\n  }\n  attr {\n    key: &quot;ellipsis_mask&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;end_mask&quot;\n    value {\n      i: 1\n    }\n  }\n  attr {\n    key: &quot;new_axis_mask&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;shrink_axis_mask&quot;\n    value {\n      i: 2\n    }\n  }\n}\nnode {\n  name: &quot;loss/final_loss/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;loss/final_loss/strided_slice&quot;\n  input: &quot;loss/loss_at0/sub_3&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/final_loss/strided_slice_1/stack&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\000\\000\\000\\000\\001\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/final_loss/strided_slice_1/stack_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\000\\000\\000\\000\\002\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/final_loss/strided_slice_1/stack_2&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\001\\000\\000\\000\\001\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;loss/final_loss/strided_slice_1&quot;\n  op: &quot;StridedSlice&quot;\n  input: &quot;qy/prob&quot;\n  input: &quot;loss/final_loss/strided_slice_1/stack&quot;\n  input: &quot;loss/final_loss/strided_slice_1/stack_1&quot;\n  input: &quot;loss/final_loss/strided_slice_1/stack_2&quot;\n  attr {\n    key: &quot;Index&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;begin_mask&quot;\n    value {\n      i: 1\n    }\n  }\n  attr {\n    key: &quot;ellipsis_mask&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;end_mask&quot;\n    value {\n      i: 1\n    }\n  }\n  attr {\n    key: &quot;new_axis_mask&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;shrink_axis_mask&quot;\n    value {\n      i: 2\n    }\n  }\n}\nnode {\n  name: &quot;loss/final_loss/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;loss/final_loss/strided_slice_1&quot;\n  input: &quot;loss/loss_at1/sub_3&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;loss/final_loss/AddN&quot;\n  op: &quot;AddN&quot;\n  input: &quot;loss/neg_entropy/Neg&quot;\n  input: &quot;loss/final_loss/mul&quot;\n  input: &quot;loss/final_loss/mul_1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 3\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/final_loss/AddN&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/grad_ys_0&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 1.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/Fill&quot;\n  op: &quot;Fill&quot;\n  input: &quot;gradients/Shape&quot;\n  input: &quot;gradients/grad_ys_0&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/AddN_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/Fill&quot;\n}\nnode {\n  name: &quot;gradients/loss/final_loss/AddN_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/Fill&quot;\n  input: &quot;^gradients/loss/final_loss/AddN_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/Fill&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/AddN_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/Fill&quot;\n  input: &quot;^gradients/loss/final_loss/AddN_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/Fill&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/AddN_grad/tuple/control_dependency_2&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/Fill&quot;\n  input: &quot;^gradients/loss/final_loss/AddN_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/Fill&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/neg_entropy/Neg_grad/Neg&quot;\n  op: &quot;Neg&quot;\n  input: &quot;gradients/loss/final_loss/AddN_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/final_loss/strided_slice&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/sub_3&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/final_loss/mul_grad/Shape&quot;\n  input: &quot;gradients/loss/final_loss/mul_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/final_loss/AddN_grad/tuple/control_dependency_1&quot;\n  input: &quot;loss/loss_at0/sub_3&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/final_loss/mul_grad/mul&quot;\n  input: &quot;gradients/loss/final_loss/mul_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/final_loss/mul_grad/Sum&quot;\n  input: &quot;gradients/loss/final_loss/mul_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;loss/final_loss/strided_slice&quot;\n  input: &quot;gradients/loss/final_loss/AddN_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/final_loss/mul_grad/mul_1&quot;\n  input: &quot;gradients/loss/final_loss/mul_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/final_loss/mul_grad/Sum_1&quot;\n  input: &quot;gradients/loss/final_loss/mul_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/final_loss/mul_grad/Reshape&quot;\n  input: &quot;^gradients/loss/final_loss/mul_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/final_loss/mul_grad/Reshape&quot;\n  input: &quot;^gradients/loss/final_loss/mul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/final_loss/mul_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/final_loss/mul_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/final_loss/mul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/final_loss/mul_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_1_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/final_loss/strided_slice_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_1_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/sub_3&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_1_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/final_loss/mul_1_grad/Shape&quot;\n  input: &quot;gradients/loss/final_loss/mul_1_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_1_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/final_loss/AddN_grad/tuple/control_dependency_2&quot;\n  input: &quot;loss/loss_at1/sub_3&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_1_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/final_loss/mul_1_grad/mul&quot;\n  input: &quot;gradients/loss/final_loss/mul_1_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_1_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/final_loss/mul_1_grad/Sum&quot;\n  input: &quot;gradients/loss/final_loss/mul_1_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_1_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;loss/final_loss/strided_slice_1&quot;\n  input: &quot;gradients/loss/final_loss/AddN_grad/tuple/control_dependency_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_1_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/final_loss/mul_1_grad/mul_1&quot;\n  input: &quot;gradients/loss/final_loss/mul_1_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_1_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/final_loss/mul_1_grad/Sum_1&quot;\n  input: &quot;gradients/loss/final_loss/mul_1_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_1_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/final_loss/mul_1_grad/Reshape&quot;\n  input: &quot;^gradients/loss/final_loss/mul_1_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_1_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/final_loss/mul_1_grad/Reshape&quot;\n  input: &quot;^gradients/loss/final_loss/mul_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/final_loss/mul_1_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/mul_1_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/final_loss/mul_1_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/final_loss/mul_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/final_loss/mul_1_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape_2_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape_2_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/neg_entropy/Neg_grad/Neg&quot;\n  input: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape_2_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/strided_slice_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;qy/prob&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/strided_slice_grad/StridedSliceGrad&quot;\n  op: &quot;StridedSliceGrad&quot;\n  input: &quot;gradients/loss/final_loss/strided_slice_grad/Shape&quot;\n  input: &quot;loss/final_loss/strided_slice/stack&quot;\n  input: &quot;loss/final_loss/strided_slice/stack_1&quot;\n  input: &quot;loss/final_loss/strided_slice/stack_2&quot;\n  input: &quot;gradients/loss/final_loss/mul_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;Index&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;begin_mask&quot;\n    value {\n      i: 1\n    }\n  }\n  attr {\n    key: &quot;ellipsis_mask&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;end_mask&quot;\n    value {\n      i: 1\n    }\n  }\n  attr {\n    key: &quot;new_axis_mask&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;shrink_axis_mask&quot;\n    value {\n      i: 2\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_3_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/add_4&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_3_grad/Shape_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_3_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at0/sub_3_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/sub_3_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_3_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/final_loss/mul_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at0/sub_3_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_3_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/sub_3_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at0/sub_3_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_3_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/final_loss/mul_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at0/sub_3_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_3_grad/Neg&quot;\n  op: &quot;Neg&quot;\n  input: &quot;gradients/loss/loss_at0/sub_3_grad/Sum_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_3_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/sub_3_grad/Neg&quot;\n  input: &quot;gradients/loss/loss_at0/sub_3_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_3_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/sub_3_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/sub_3_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_3_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/sub_3_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/sub_3_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/sub_3_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_3_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/sub_3_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at0/sub_3_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/sub_3_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/strided_slice_1_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;qy/prob&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/final_loss/strided_slice_1_grad/StridedSliceGrad&quot;\n  op: &quot;StridedSliceGrad&quot;\n  input: &quot;gradients/loss/final_loss/strided_slice_1_grad/Shape&quot;\n  input: &quot;loss/final_loss/strided_slice_1/stack&quot;\n  input: &quot;loss/final_loss/strided_slice_1/stack_1&quot;\n  input: &quot;loss/final_loss/strided_slice_1/stack_2&quot;\n  input: &quot;gradients/loss/final_loss/mul_1_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;Index&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;begin_mask&quot;\n    value {\n      i: 1\n    }\n  }\n  attr {\n    key: &quot;ellipsis_mask&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;end_mask&quot;\n    value {\n      i: 1\n    }\n  }\n  attr {\n    key: &quot;new_axis_mask&quot;\n    value {\n      i: 0\n    }\n  }\n  attr {\n    key: &quot;shrink_axis_mask&quot;\n    value {\n      i: 2\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_3_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/add_4&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_3_grad/Shape_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_3_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at1/sub_3_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/sub_3_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_3_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/final_loss/mul_1_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at1/sub_3_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_3_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/sub_3_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at1/sub_3_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_3_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/final_loss/mul_1_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at1/sub_3_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_3_grad/Neg&quot;\n  op: &quot;Neg&quot;\n  input: &quot;gradients/loss/loss_at1/sub_3_grad/Sum_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_3_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/sub_3_grad/Neg&quot;\n  input: &quot;gradients/loss/loss_at1/sub_3_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_3_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/sub_3_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/sub_3_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_3_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/sub_3_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/sub_3_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/sub_3_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_3_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/sub_3_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at1/sub_3_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/sub_3_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/zeros_like&quot;\n  op: &quot;ZerosLike&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/ExpandDims/dim&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: -1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/ExpandDims&quot;\n  op: &quot;ExpandDims&quot;\n  input: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape_2_grad/Reshape&quot;\n  input: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/ExpandDims/dim&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tdim&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/ExpandDims&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/LogSoftmax&quot;\n  op: &quot;LogSoftmax&quot;\n  input: &quot;loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/Neg&quot;\n  op: &quot;Neg&quot;\n  input: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/LogSoftmax&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/ExpandDims_1/dim&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: -1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/ExpandDims_1&quot;\n  op: &quot;ExpandDims&quot;\n  input: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape_2_grad/Reshape&quot;\n  input: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/ExpandDims_1/dim&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tdim&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/ExpandDims_1&quot;\n  input: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/Neg&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/mul&quot;\n  input: &quot;^gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/mul_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/mul&quot;\n  input: &quot;^gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/mul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/mul_1&quot;\n  input: &quot;^gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/mul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_4_grad/Shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_4_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/sub_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_4_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at0/add_4_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/add_4_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_4_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/sub_3_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at0/add_4_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_4_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/add_4_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at0/add_4_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_4_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/sub_3_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at0/add_4_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_4_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/add_4_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at0/add_4_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_4_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/add_4_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/add_4_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_4_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/add_4_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/add_4_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/add_4_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_4_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/add_4_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at0/add_4_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/add_4_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_4_grad/Shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_4_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/sub_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_4_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at1/add_4_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/add_4_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_4_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/sub_3_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at1/add_4_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_4_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/add_4_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at1/add_4_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_4_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/sub_3_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at1/add_4_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_4_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/add_4_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at1/add_4_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_4_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/add_4_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/add_4_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_4_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/add_4_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/add_4_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/add_4_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_4_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/add_4_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at1/add_4_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/add_4_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;qy/logit/Relu&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape_1_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;qy/prob&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape_1_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape_1_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/value_grad/zeros_like&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/value_grad/Select&quot;\n  op: &quot;Select&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/Greater&quot;\n  input: &quot;gradients/loss/loss_at0/add_4_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/value_grad/zeros_like&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/value_grad/Select_1&quot;\n  op: &quot;Select&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/Greater&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/value_grad/zeros_like&quot;\n  input: &quot;gradients/loss/loss_at0/add_4_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/value_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/value_grad/Select&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/value_grad/Select_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/value_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/value_grad/Select&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/value_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/mean_squared_error/value_grad/Select&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/value_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/value_grad/Select_1&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/value_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/mean_squared_error/value_grad/Select_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_2_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/mul&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_2_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/mul_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_2_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at0/sub_2_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/sub_2_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_2_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/add_4_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at0/sub_2_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_2_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/sub_2_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at0/sub_2_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_2_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/add_4_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at0/sub_2_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_2_grad/Neg&quot;\n  op: &quot;Neg&quot;\n  input: &quot;gradients/loss/loss_at0/sub_2_grad/Sum_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_2_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/sub_2_grad/Neg&quot;\n  input: &quot;gradients/loss/loss_at0/sub_2_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_2_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/sub_2_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/sub_2_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_2_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/sub_2_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/sub_2_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/sub_2_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_2_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/sub_2_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at0/sub_2_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/sub_2_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/value_grad/zeros_like&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/value_grad/Select&quot;\n  op: &quot;Select&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/Greater&quot;\n  input: &quot;gradients/loss/loss_at1/add_4_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/value_grad/zeros_like&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/value_grad/Select_1&quot;\n  op: &quot;Select&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/Greater&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/value_grad/zeros_like&quot;\n  input: &quot;gradients/loss/loss_at1/add_4_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/value_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/value_grad/Select&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/value_grad/Select_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/value_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/value_grad/Select&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/value_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/mean_squared_error/value_grad/Select&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/value_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/value_grad/Select_1&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/value_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/mean_squared_error/value_grad/Select_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_2_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/mul&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_2_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/mul_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_2_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at1/sub_2_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/sub_2_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_2_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/add_4_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at1/sub_2_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_2_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/sub_2_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at1/sub_2_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_2_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/add_4_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at1/sub_2_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_2_grad/Neg&quot;\n  op: &quot;Neg&quot;\n  input: &quot;gradients/loss/loss_at1/sub_2_grad/Sum_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_2_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/sub_2_grad/Neg&quot;\n  input: &quot;gradients/loss/loss_at1/sub_2_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_2_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/sub_2_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/sub_2_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_2_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/sub_2_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/sub_2_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/sub_2_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_2_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/sub_2_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at1/sub_2_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/sub_2_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/Shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/Shape_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/RealDiv&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/value_grad/tuple/control_dependency&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/Select&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/RealDiv&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/Neg&quot;\n  op: &quot;Neg&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/Sum_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/RealDiv_1&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/Neg&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/Select&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/RealDiv_2&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/RealDiv_1&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/Select&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/value_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/RealDiv_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/mul&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/div_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/div_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/div_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/mean_squared_error/div_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/div_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/mean_squared_error/div_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_grad/Shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/Sum&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at0/mul_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/mul_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at0/sub_2_grad/tuple/control_dependency&quot;\n  input: &quot;loss/loss_at0/Sum&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/mul_grad/mul&quot;\n  input: &quot;gradients/loss/loss_at0/mul_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/mul_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at0/mul_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;loss/loss_at0/mul/x&quot;\n  input: &quot;gradients/loss/loss_at0/sub_2_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/mul_grad/mul_1&quot;\n  input: &quot;gradients/loss/loss_at0/mul_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/mul_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at0/mul_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/mul_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/mul_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/mul_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/mul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/mul_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/mul_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at0/mul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/mul_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_1_grad/Shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_1_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/Sum_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_1_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at0/mul_1_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/mul_1_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_1_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at0/sub_2_grad/tuple/control_dependency_1&quot;\n  input: &quot;loss/loss_at0/Sum_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_1_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/mul_1_grad/mul&quot;\n  input: &quot;gradients/loss/loss_at0/mul_1_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_1_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/mul_1_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at0/mul_1_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_1_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;loss/loss_at0/mul_1/x&quot;\n  input: &quot;gradients/loss/loss_at0/sub_2_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_1_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/mul_1_grad/mul_1&quot;\n  input: &quot;gradients/loss/loss_at0/mul_1_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_1_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/mul_1_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at0/mul_1_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_1_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/mul_1_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/mul_1_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_1_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/mul_1_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/mul_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/mul_1_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mul_1_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/mul_1_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at0/mul_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/mul_1_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/Shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/Shape_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/RealDiv&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/value_grad/tuple/control_dependency&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/Select&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/RealDiv&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/Neg&quot;\n  op: &quot;Neg&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/Sum_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/RealDiv_1&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/Neg&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/Select&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/RealDiv_2&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/RealDiv_1&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/Select&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/value_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/RealDiv_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/mul&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/div_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/div_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/div_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/mean_squared_error/div_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/div_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/mean_squared_error/div_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_grad/Shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/Sum&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at1/mul_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/mul_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at1/sub_2_grad/tuple/control_dependency&quot;\n  input: &quot;loss/loss_at1/Sum&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/mul_grad/mul&quot;\n  input: &quot;gradients/loss/loss_at1/mul_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/mul_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at1/mul_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;loss/loss_at1/mul/x&quot;\n  input: &quot;gradients/loss/loss_at1/sub_2_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/mul_grad/mul_1&quot;\n  input: &quot;gradients/loss/loss_at1/mul_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/mul_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at1/mul_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/mul_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/mul_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/mul_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/mul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/mul_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/mul_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at1/mul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/mul_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_1_grad/Shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_1_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/Sum_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_1_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at1/mul_1_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/mul_1_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_1_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at1/sub_2_grad/tuple/control_dependency_1&quot;\n  input: &quot;loss/loss_at1/Sum_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_1_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/mul_1_grad/mul&quot;\n  input: &quot;gradients/loss/loss_at1/mul_1_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_1_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/mul_1_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at1/mul_1_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_1_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;loss/loss_at1/mul_1/x&quot;\n  input: &quot;gradients/loss/loss_at1/sub_2_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_1_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/mul_1_grad/mul_1&quot;\n  input: &quot;gradients/loss/loss_at1/mul_1_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_1_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/mul_1_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at1/mul_1_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_1_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/mul_1_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/mul_1_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_1_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/mul_1_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/mul_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/mul_1_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mul_1_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/mul_1_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at1/mul_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/mul_1_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Sum_1_grad/Reshape/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Sum_1_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Sum_1_grad/Reshape/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Sum_1_grad/Tile/multiples&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Sum_1_grad/Tile&quot;\n  op: &quot;Tile&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Sum_1_grad/Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Sum_1_grad/Tile/multiples&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tmultiples&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Select_grad/zeros_like&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Select_grad/Select&quot;\n  op: &quot;Select&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/Equal&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Select_grad/zeros_like&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Select_grad/Select_1&quot;\n  op: &quot;Select&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/Equal&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Select_grad/zeros_like&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/div_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Select_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/Select_grad/Select&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/Select_grad/Select_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Select_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Select_grad/Select&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/Select_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/mean_squared_error/Select_grad/Select&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Select_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Select_grad/Select_1&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/Select_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/mean_squared_error/Select_grad/Select_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/add_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_grad/Size&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 2\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_grad/add&quot;\n  op: &quot;Add&quot;\n  input: &quot;loss/loss_at0/Sum/reduction_indices&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/Size&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_grad/mod&quot;\n  op: &quot;FloorMod&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/add&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/Size&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_grad/Shape_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_grad/range/start&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_grad/range/delta&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_grad/range&quot;\n  op: &quot;Range&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/range/start&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/Size&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/range/delta&quot;\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_grad/Fill/value&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_grad/Fill&quot;\n  op: &quot;Fill&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/Shape_1&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/Fill/value&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_grad/DynamicStitch&quot;\n  op: &quot;DynamicStitch&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/range&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/mod&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/Fill&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_grad/Maximum/y&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_grad/Maximum&quot;\n  op: &quot;Maximum&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/DynamicStitch&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/Maximum/y&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_grad/floordiv&quot;\n  op: &quot;FloorDiv&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/Maximum&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/mul_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/DynamicStitch&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_grad/Tile&quot;\n  op: &quot;Tile&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/floordiv&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tmultiples&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_1_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/add_3&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_1_grad/Size&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 2\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_1_grad/add&quot;\n  op: &quot;Add&quot;\n  input: &quot;loss/loss_at0/Sum_1/reduction_indices&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/Size&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_1_grad/mod&quot;\n  op: &quot;FloorMod&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/add&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/Size&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_1_grad/Shape_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_1_grad/range/start&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_1_grad/range/delta&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_1_grad/range&quot;\n  op: &quot;Range&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/range/start&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/Size&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/range/delta&quot;\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_1_grad/Fill/value&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_1_grad/Fill&quot;\n  op: &quot;Fill&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/Shape_1&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/Fill/value&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_1_grad/DynamicStitch&quot;\n  op: &quot;DynamicStitch&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/range&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/mod&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/Fill&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_1_grad/Maximum/y&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_1_grad/Maximum&quot;\n  op: &quot;Maximum&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/DynamicStitch&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/Maximum/y&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_1_grad/floordiv&quot;\n  op: &quot;FloorDiv&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/Maximum&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_1_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/mul_1_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/DynamicStitch&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Sum_1_grad/Tile&quot;\n  op: &quot;Tile&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/floordiv&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tmultiples&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Sum_1_grad/Reshape/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Sum_1_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Sum_1_grad/Reshape/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Sum_1_grad/Tile/multiples&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Sum_1_grad/Tile&quot;\n  op: &quot;Tile&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Sum_1_grad/Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Sum_1_grad/Tile/multiples&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tmultiples&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Select_grad/zeros_like&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Select_grad/Select&quot;\n  op: &quot;Select&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/Equal&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Select_grad/zeros_like&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Select_grad/Select_1&quot;\n  op: &quot;Select&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/Equal&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Select_grad/zeros_like&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/div_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Select_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/Select_grad/Select&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/Select_grad/Select_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Select_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Select_grad/Select&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/Select_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/mean_squared_error/Select_grad/Select&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Select_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Select_grad/Select_1&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/Select_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/mean_squared_error/Select_grad/Select_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/add_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_grad/Size&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 2\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_grad/add&quot;\n  op: &quot;Add&quot;\n  input: &quot;loss/loss_at1/Sum/reduction_indices&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/Size&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_grad/mod&quot;\n  op: &quot;FloorMod&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/add&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/Size&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_grad/Shape_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_grad/range/start&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_grad/range/delta&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_grad/range&quot;\n  op: &quot;Range&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/range/start&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/Size&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/range/delta&quot;\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_grad/Fill/value&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_grad/Fill&quot;\n  op: &quot;Fill&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/Shape_1&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/Fill/value&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_grad/DynamicStitch&quot;\n  op: &quot;DynamicStitch&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/range&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/mod&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/Fill&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_grad/Maximum/y&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_grad/Maximum&quot;\n  op: &quot;Maximum&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/DynamicStitch&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/Maximum/y&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_grad/floordiv&quot;\n  op: &quot;FloorDiv&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/Maximum&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/mul_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/DynamicStitch&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_grad/Tile&quot;\n  op: &quot;Tile&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/floordiv&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tmultiples&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_1_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/add_3&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_1_grad/Size&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 2\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_1_grad/add&quot;\n  op: &quot;Add&quot;\n  input: &quot;loss/loss_at1/Sum_1/reduction_indices&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/Size&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_1_grad/mod&quot;\n  op: &quot;FloorMod&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/add&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/Size&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_1_grad/Shape_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_1_grad/range/start&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_1_grad/range/delta&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_1_grad/range&quot;\n  op: &quot;Range&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/range/start&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/Size&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/range/delta&quot;\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_1_grad/Fill/value&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_1_grad/Fill&quot;\n  op: &quot;Fill&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/Shape_1&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/Fill/value&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_1_grad/DynamicStitch&quot;\n  op: &quot;DynamicStitch&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/range&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/mod&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/Fill&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_1_grad/Maximum/y&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_1_grad/Maximum&quot;\n  op: &quot;Maximum&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/DynamicStitch&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/Maximum/y&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_1_grad/floordiv&quot;\n  op: &quot;FloorDiv&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/Maximum&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/Sum_1_grad/Shape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_1_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/mul_1_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/DynamicStitch&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Sum_1_grad/Tile&quot;\n  op: &quot;Tile&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/floordiv&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tmultiples&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Sum_grad/Reshape/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\001\\000\\000\\000\\001\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Sum_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Sum_1_grad/Tile&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Sum_grad/Reshape/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Sum_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/Mul&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Sum_grad/Tile&quot;\n  op: &quot;Tile&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Sum_grad/Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Sum_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tmultiples&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_1_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/add&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_1_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/truediv&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_1_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at0/add_1_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/add_1_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_1_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/Tile&quot;\n  input: &quot;gradients/loss/loss_at0/add_1_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_1_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/add_1_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at0/add_1_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_1_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_grad/Tile&quot;\n  input: &quot;gradients/loss/loss_at0/add_1_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_1_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/add_1_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at0/add_1_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_1_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/add_1_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/add_1_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_1_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/add_1_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/add_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/add_1_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_1_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/add_1_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at0/add_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/add_1_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_3_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/add_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_3_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/truediv_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_3_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at0/add_3_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/add_3_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_3_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/Tile&quot;\n  input: &quot;gradients/loss/loss_at0/add_3_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_3_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/add_3_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at0/add_3_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_3_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/Sum_1_grad/Tile&quot;\n  input: &quot;gradients/loss/loss_at0/add_3_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_3_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/add_3_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at0/add_3_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_3_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/add_3_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/add_3_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_3_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/add_3_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/add_3_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/add_3_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_3_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/add_3_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at0/add_3_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/add_3_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Sum_grad/Reshape/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\001\\000\\000\\000\\001\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Sum_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Sum_1_grad/Tile&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Sum_grad/Reshape/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Sum_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/Mul&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Sum_grad/Tile&quot;\n  op: &quot;Tile&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Sum_grad/Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Sum_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tmultiples&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_1_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/add&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_1_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/truediv&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_1_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at1/add_1_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/add_1_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_1_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/Tile&quot;\n  input: &quot;gradients/loss/loss_at1/add_1_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_1_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/add_1_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at1/add_1_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_1_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_grad/Tile&quot;\n  input: &quot;gradients/loss/loss_at1/add_1_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_1_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/add_1_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at1/add_1_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_1_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/add_1_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/add_1_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_1_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/add_1_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/add_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/add_1_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_1_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/add_1_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at1/add_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/add_1_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_3_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/add_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_3_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/truediv_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_3_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at1/add_3_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/add_3_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_3_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/Tile&quot;\n  input: &quot;gradients/loss/loss_at1/add_3_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_3_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/add_3_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at1/add_3_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_3_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/Sum_1_grad/Tile&quot;\n  input: &quot;gradients/loss/loss_at1/add_3_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_3_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/add_3_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at1/add_3_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_3_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/add_3_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/add_3_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_3_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/add_3_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/add_3_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/add_3_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_3_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/add_3_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at1/add_3_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/add_3_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/loss/final_loss/strided_slice_grad/StridedSliceGrad&quot;\n  input: &quot;gradients/loss/final_loss/strided_slice_1_grad/StridedSliceGrad&quot;\n  input: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape_1_grad/Reshape&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 3\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/final_loss/strided_slice_grad/StridedSliceGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/prob_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/AddN&quot;\n  input: &quot;qy/prob&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/prob_grad/Sum/reduction_indices&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        int_val: 1\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/prob_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/qy/prob_grad/mul&quot;\n  input: &quot;gradients/qy/prob_grad/Sum/reduction_indices&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/prob_grad/Reshape/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\377\\377\\377\\377\\001\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/prob_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/qy/prob_grad/Sum&quot;\n  input: &quot;gradients/qy/prob_grad/Reshape/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/prob_grad/sub&quot;\n  op: &quot;Sub&quot;\n  input: &quot;gradients/AddN&quot;\n  input: &quot;gradients/qy/prob_grad/Reshape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/prob_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/qy/prob_grad/sub&quot;\n  input: &quot;qy/prob&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/SquaredDifference&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/Shape_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Sum_grad/Tile&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/ToFloat_3/x&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/mul&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/SquaredDifference&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Sum_grad/Tile&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/mul_1&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/Mul_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/Mul_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/Mul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/mean_squared_error/Mul_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/Mul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/mean_squared_error/Mul_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/num_present_grad/Reshape/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\001\\000\\000\\000\\001\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/num_present_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Select_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/num_present_grad/Reshape/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/num_present_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/num_present/broadcast_weights&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/num_present_grad/Tile&quot;\n  op: &quot;Tile&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/num_present_grad/Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/num_present_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tmultiples&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_grad/Shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/Log_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at0/add_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/add_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/add_1_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at0/add_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/add_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at0/add_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/add_1_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at0/add_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/add_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at0/add_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/add_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/add_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/add_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/add_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/add_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/add_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at0/add_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/add_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/Square&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at0/qz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_grad/RealDiv&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/loss/loss_at0/add_1_grad/tuple/control_dependency_1&quot;\n  input: &quot;graphs/hot_at0/qz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_grad/RealDiv&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_grad/Neg&quot;\n  op: &quot;Neg&quot;\n  input: &quot;loss/loss_at0/Square&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_grad/RealDiv_1&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_grad/Neg&quot;\n  input: &quot;graphs/hot_at0/qz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_grad/RealDiv_2&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_grad/RealDiv_1&quot;\n  input: &quot;graphs/hot_at0/qz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at0/add_1_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_grad/RealDiv_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_grad/mul&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/truediv_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/truediv_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/truediv_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/truediv_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at0/truediv_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/truediv_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_2_grad/Shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_2_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/Log_3&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_2_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at0/add_2_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/add_2_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_2_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/add_3_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at0/add_2_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_2_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/add_2_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at0/add_2_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_2_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/add_3_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at0/add_2_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_2_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/add_2_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at0/add_2_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_2_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/add_2_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/add_2_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_2_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/add_2_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/add_2_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/add_2_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/add_2_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/add_2_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at0/add_2_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/add_2_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_1_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/Square_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_1_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at0/pz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_1_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_1_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_1_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_1_grad/RealDiv&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/loss/loss_at0/add_3_grad/tuple/control_dependency_1&quot;\n  input: &quot;graphs/hot_at0/pz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_1_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_1_grad/RealDiv&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_1_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_1_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_1_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_1_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_1_grad/Neg&quot;\n  op: &quot;Neg&quot;\n  input: &quot;loss/loss_at0/Square_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_1_grad/RealDiv_1&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_1_grad/Neg&quot;\n  input: &quot;graphs/hot_at0/pz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_1_grad/RealDiv_2&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_1_grad/RealDiv_1&quot;\n  input: &quot;graphs/hot_at0/pz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_1_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at0/add_3_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_1_grad/RealDiv_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_1_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_1_grad/mul&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_1_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_1_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_1_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_1_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_1_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/truediv_1_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/truediv_1_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_1_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_1_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/truediv_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/truediv_1_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/truediv_1_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_1_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at0/truediv_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/truediv_1_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/SquaredDifference&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/Shape_1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Sum_grad/Tile&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/ToFloat_3/x&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/mul&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/SquaredDifference&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Sum_grad/Tile&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/mul_1&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/Mul_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/Mul_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/Mul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/mean_squared_error/Mul_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/Mul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/mean_squared_error/Mul_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/num_present_grad/Reshape/shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\001\\000\\000\\000\\001\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/num_present_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Select_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/num_present_grad/Reshape/shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/num_present_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/num_present/broadcast_weights&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/num_present_grad/Tile&quot;\n  op: &quot;Tile&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/num_present_grad/Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/num_present_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tmultiples&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_grad/Shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/Log_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at1/add_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/add_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/add_1_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at1/add_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/add_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at1/add_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/add_1_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at1/add_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/add_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at1/add_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/add_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/add_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/add_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/add_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/add_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/add_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at1/add_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/add_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/Square&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at1/qz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_grad/RealDiv&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/loss/loss_at1/add_1_grad/tuple/control_dependency_1&quot;\n  input: &quot;graphs/hot_at1/qz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_grad/RealDiv&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_grad/Neg&quot;\n  op: &quot;Neg&quot;\n  input: &quot;loss/loss_at1/Square&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_grad/RealDiv_1&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_grad/Neg&quot;\n  input: &quot;graphs/hot_at1/qz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_grad/RealDiv_2&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_grad/RealDiv_1&quot;\n  input: &quot;graphs/hot_at1/qz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at1/add_1_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_grad/RealDiv_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_grad/mul&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/truediv_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/truediv_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/truediv_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/truediv_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at1/truediv_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/truediv_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_2_grad/Shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_2_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/Log_3&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_2_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at1/add_2_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/add_2_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_2_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/add_3_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at1/add_2_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_2_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/add_2_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at1/add_2_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_2_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/add_3_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at1/add_2_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_2_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/add_2_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at1/add_2_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_2_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/add_2_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/add_2_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_2_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/add_2_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/add_2_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/add_2_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/add_2_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/add_2_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at1/add_2_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/add_2_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_1_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/Square_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_1_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at1/pz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_1_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_1_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_1_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_1_grad/RealDiv&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/loss/loss_at1/add_3_grad/tuple/control_dependency_1&quot;\n  input: &quot;graphs/hot_at1/pz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_1_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_1_grad/RealDiv&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_1_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_1_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_1_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_1_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_1_grad/Neg&quot;\n  op: &quot;Neg&quot;\n  input: &quot;loss/loss_at1/Square_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_1_grad/RealDiv_1&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_1_grad/Neg&quot;\n  input: &quot;graphs/hot_at1/pz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_1_grad/RealDiv_2&quot;\n  op: &quot;RealDiv&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_1_grad/RealDiv_1&quot;\n  input: &quot;graphs/hot_at1/pz/zv/Softplus&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_1_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at1/add_3_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_1_grad/RealDiv_2&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_1_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_1_grad/mul&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_1_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_1_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_1_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_1_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_1_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/truediv_1_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/truediv_1_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_1_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_1_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/truediv_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/truediv_1_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/truediv_1_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_1_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at1/truediv_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/truediv_1_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_1&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape_grad/Reshape&quot;\n  input: &quot;gradients/qy/prob_grad/mul_1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/neg_entropy/softmax_cross_entropy_with_logits/Reshape_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/logit/Relu_grad/ReluGrad&quot;\n  op: &quot;ReluGrad&quot;\n  input: &quot;gradients/AddN_1&quot;\n  input: &quot;qy/logit/Relu&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/Shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/num_present/broadcast_weights/ones_like&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/num_present_grad/Tile&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/num_present/broadcast_weights/ones_like&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/mul&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;loss/loss_at0/mean_squared_error/num_present/Select&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/num_present_grad/Tile&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/mul_1&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Log_1_grad/Reciprocal&quot;\n  op: &quot;Reciprocal&quot;\n  input: &quot;graphs/hot_at0/qz/zv/Softplus&quot;\n  input: &quot;^gradients/loss/loss_at0/add_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Log_1_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at0/add_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at0/Log_1_grad/Reciprocal&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Square_grad/mul/x&quot;\n  op: &quot;Const&quot;\n  input: &quot;^gradients/loss/loss_at0/truediv_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 2.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Square_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at0/Square_grad/mul/x&quot;\n  input: &quot;loss/loss_at0/sub&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Square_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at0/Square_grad/mul&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Log_3_grad/Reciprocal&quot;\n  op: &quot;Reciprocal&quot;\n  input: &quot;graphs/hot_at0/pz/zv/Softplus&quot;\n  input: &quot;^gradients/loss/loss_at0/add_2_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Log_3_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at0/add_2_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at0/Log_3_grad/Reciprocal&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Square_1_grad/mul/x&quot;\n  op: &quot;Const&quot;\n  input: &quot;^gradients/loss/loss_at0/truediv_1_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 2.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Square_1_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at0/Square_1_grad/mul/x&quot;\n  input: &quot;loss/loss_at0/sub_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/Square_1_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_1_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at0/Square_1_grad/mul&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/Shape&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/num_present/broadcast_weights/ones_like&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/num_present_grad/Tile&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/num_present/broadcast_weights/ones_like&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/mul&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;loss/loss_at1/mean_squared_error/num_present/Select&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/num_present_grad/Tile&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/mul_1&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Log_1_grad/Reciprocal&quot;\n  op: &quot;Reciprocal&quot;\n  input: &quot;graphs/hot_at1/qz/zv/Softplus&quot;\n  input: &quot;^gradients/loss/loss_at1/add_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Log_1_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at1/add_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at1/Log_1_grad/Reciprocal&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Square_grad/mul/x&quot;\n  op: &quot;Const&quot;\n  input: &quot;^gradients/loss/loss_at1/truediv_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 2.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Square_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at1/Square_grad/mul/x&quot;\n  input: &quot;loss/loss_at1/sub&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Square_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at1/Square_grad/mul&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Log_3_grad/Reciprocal&quot;\n  op: &quot;Reciprocal&quot;\n  input: &quot;graphs/hot_at1/pz/zv/Softplus&quot;\n  input: &quot;^gradients/loss/loss_at1/add_2_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Log_3_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at1/add_2_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at1/Log_3_grad/Reciprocal&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Square_1_grad/mul/x&quot;\n  op: &quot;Const&quot;\n  input: &quot;^gradients/loss/loss_at1/truediv_1_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 2.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Square_1_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at1/Square_1_grad/mul/x&quot;\n  input: &quot;loss/loss_at1/sub_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/Square_1_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_1_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at1/Square_1_grad/mul&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/logit/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/qy/logit/Relu_grad/ReluGrad&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/logit/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/qy/logit/Relu_grad/ReluGrad&quot;\n  input: &quot;^gradients/qy/logit/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/qy/logit/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/qy/logit/Relu_grad/ReluGrad&quot;\n  input: &quot;^gradients/qy/logit/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/qy/logit/Relu_grad/ReluGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/logit/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/qy/logit/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/qy/logit/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/qy/logit/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights/ones_like_grad/Const&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\000\\000\\000\\000\\001\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights/ones_like_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/num_present/broadcast_weights/ones_like_grad/Const&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at0/qz/z_sample&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at0/qz/zm/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at0/sub_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/sub_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/Square_grad/mul_1&quot;\n  input: &quot;gradients/loss/loss_at0/sub_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/sub_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at0/sub_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/Square_grad/mul_1&quot;\n  input: &quot;gradients/loss/loss_at0/sub_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_grad/Neg&quot;\n  op: &quot;Neg&quot;\n  input: &quot;gradients/loss/loss_at0/sub_grad/Sum_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/sub_grad/Neg&quot;\n  input: &quot;gradients/loss/loss_at0/sub_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/sub_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/sub_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/sub_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/sub_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/sub_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/sub_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at0/sub_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/sub_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_2&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_1_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at0/Log_3_grad/mul&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/truediv_1_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/pz/zv/Softplus_grad/SoftplusGrad&quot;\n  op: &quot;SoftplusGrad&quot;\n  input: &quot;gradients/AddN_2&quot;\n  input: &quot;graphs/hot_at0/pz/zv/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_1_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at0/qz/z_sample&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_1_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at0/pz/zm/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_1_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at0/sub_1_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/sub_1_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_1_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/Square_1_grad/mul_1&quot;\n  input: &quot;gradients/loss/loss_at0/sub_1_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_1_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/sub_1_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at0/sub_1_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_1_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/Square_1_grad/mul_1&quot;\n  input: &quot;gradients/loss/loss_at0/sub_1_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_1_grad/Neg&quot;\n  op: &quot;Neg&quot;\n  input: &quot;gradients/loss/loss_at0/sub_1_grad/Sum_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_1_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/sub_1_grad/Neg&quot;\n  input: &quot;gradients/loss/loss_at0/sub_1_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_1_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/sub_1_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/sub_1_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_1_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/sub_1_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/sub_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/sub_1_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/sub_1_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/sub_1_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at0/sub_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/sub_1_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights/ones_like_grad/Const&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_INT32\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: &quot;\\000\\000\\000\\000\\001\\000\\000\\000&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights/ones_like_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/num_present/broadcast_weights/ones_like_grad/Const&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at1/qz/z_sample&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at1/qz/zm/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at1/sub_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/sub_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/Square_grad/mul_1&quot;\n  input: &quot;gradients/loss/loss_at1/sub_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/sub_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at1/sub_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/Square_grad/mul_1&quot;\n  input: &quot;gradients/loss/loss_at1/sub_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_grad/Neg&quot;\n  op: &quot;Neg&quot;\n  input: &quot;gradients/loss/loss_at1/sub_grad/Sum_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/sub_grad/Neg&quot;\n  input: &quot;gradients/loss/loss_at1/sub_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/sub_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/sub_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/sub_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/sub_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/sub_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/sub_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at1/sub_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/sub_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_3&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_1_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at1/Log_3_grad/mul&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/truediv_1_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/pz/zv/Softplus_grad/SoftplusGrad&quot;\n  op: &quot;SoftplusGrad&quot;\n  input: &quot;gradients/AddN_3&quot;\n  input: &quot;graphs/hot_at1/pz/zv/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_1_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at1/qz/z_sample&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_1_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at1/pz/zm/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_1_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at1/sub_1_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/sub_1_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_1_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/Square_1_grad/mul_1&quot;\n  input: &quot;gradients/loss/loss_at1/sub_1_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_1_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/sub_1_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at1/sub_1_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_1_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/Square_1_grad/mul_1&quot;\n  input: &quot;gradients/loss/loss_at1/sub_1_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_1_grad/Neg&quot;\n  op: &quot;Neg&quot;\n  input: &quot;gradients/loss/loss_at1/sub_1_grad/Sum_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_1_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/sub_1_grad/Neg&quot;\n  input: &quot;gradients/loss/loss_at1/sub_1_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_1_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/sub_1_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/sub_1_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_1_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/sub_1_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/sub_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/sub_1_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/sub_1_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/sub_1_grad/Reshape_1&quot;\n  input: &quot;^gradients/loss/loss_at1/sub_1_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/sub_1_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/logit/MatMul_grad/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;gradients/qy/logit/BiasAdd_grad/tuple/control_dependency&quot;\n  input: &quot;qy/logit/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/logit/MatMul_grad/MatMul_1&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;qy/layer1/Relu&quot;\n  input: &quot;gradients/qy/logit/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/logit/MatMul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/qy/logit/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/qy/logit/MatMul_grad/MatMul_1&quot;\n}\nnode {\n  name: &quot;gradients/qy/logit/MatMul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/qy/logit/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/qy/logit/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/qy/logit/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/logit/MatMul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/qy/logit/MatMul_grad/MatMul_1&quot;\n  input: &quot;^gradients/qy/logit/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/qy/logit/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/pz/zv/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/graphs/hot_at0/pz/zv/Softplus_grad/SoftplusGrad&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/pz/zv/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at0/pz/zv/Softplus_grad/SoftplusGrad&quot;\n  input: &quot;^gradients/graphs/hot_at0/pz/zv/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/pz/zv/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/pz/zv/Softplus_grad/SoftplusGrad&quot;\n  input: &quot;^gradients/graphs/hot_at0/pz/zv/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/pz/zv/Softplus_grad/SoftplusGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/pz/zv/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/pz/zv/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/graphs/hot_at0/pz/zv/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/pz/zv/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/pz/zm/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/loss/loss_at0/sub_1_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/pz/zm/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/sub_1_grad/tuple/control_dependency_1&quot;\n  input: &quot;^gradients/graphs/hot_at0/pz/zm/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/pz/zm/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/sub_1_grad/tuple/control_dependency_1&quot;\n  input: &quot;^gradients/graphs/hot_at0/pz/zm/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/sub_1_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/pz/zm/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/pz/zm/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/graphs/hot_at0/pz/zm/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/pz/zm/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/pz/zv/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/graphs/hot_at1/pz/zv/Softplus_grad/SoftplusGrad&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/pz/zv/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at1/pz/zv/Softplus_grad/SoftplusGrad&quot;\n  input: &quot;^gradients/graphs/hot_at1/pz/zv/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/pz/zv/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/pz/zv/Softplus_grad/SoftplusGrad&quot;\n  input: &quot;^gradients/graphs/hot_at1/pz/zv/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/pz/zv/Softplus_grad/SoftplusGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/pz/zv/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/pz/zv/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/graphs/hot_at1/pz/zv/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/pz/zv/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/pz/zm/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/loss/loss_at1/sub_1_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/pz/zm/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/sub_1_grad/tuple/control_dependency_1&quot;\n  input: &quot;^gradients/graphs/hot_at1/pz/zm/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/pz/zm/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/sub_1_grad/tuple/control_dependency_1&quot;\n  input: &quot;^gradients/graphs/hot_at1/pz/zm/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/sub_1_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/pz/zm/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/pz/zm/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/graphs/hot_at1/pz/zm/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/pz/zm/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/layer1/Relu_grad/ReluGrad&quot;\n  op: &quot;ReluGrad&quot;\n  input: &quot;gradients/qy/logit/MatMul_grad/tuple/control_dependency&quot;\n  input: &quot;qy/layer1/Relu&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at0/px/output/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;x&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/scalar&quot;\n  op: &quot;Const&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/Mul_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 2.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/scalar&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/Mul_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/sub&quot;\n  op: &quot;Sub&quot;\n  input: &quot;graphs/hot_at0/px/output/BiasAdd&quot;\n  input: &quot;x&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/Mul_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/mul&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/sub&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/mul_1&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/mul_1&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Neg&quot;\n  op: &quot;Neg&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Reshape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Neg&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Neg&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Neg&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/pz/zv/MatMul_grad/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;gradients/graphs/hot_at0/pz/zv/BiasAdd_grad/tuple/control_dependency&quot;\n  input: &quot;pz/zv/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/pz/zv/MatMul_grad/MatMul_1&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at0/Add&quot;\n  input: &quot;gradients/graphs/hot_at0/pz/zv/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/pz/zv/MatMul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at0/pz/zv/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at0/pz/zv/MatMul_grad/MatMul_1&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/pz/zv/MatMul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/pz/zv/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at0/pz/zv/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/pz/zv/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/pz/zv/MatMul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/pz/zv/MatMul_grad/MatMul_1&quot;\n  input: &quot;^gradients/graphs/hot_at0/pz/zv/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/pz/zv/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/pz/zm/MatMul_grad/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;gradients/graphs/hot_at0/pz/zm/BiasAdd_grad/tuple/control_dependency&quot;\n  input: &quot;pz/zm/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/pz/zm/MatMul_grad/MatMul_1&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at0/Add&quot;\n  input: &quot;gradients/graphs/hot_at0/pz/zm/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/pz/zm/MatMul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at0/pz/zm/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at0/pz/zm/MatMul_grad/MatMul_1&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/pz/zm/MatMul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/pz/zm/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at0/pz/zm/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/pz/zm/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/pz/zm/MatMul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/pz/zm/MatMul_grad/MatMul_1&quot;\n  input: &quot;^gradients/graphs/hot_at0/pz/zm/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/pz/zm/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at1/px/output/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;x&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Shape&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/scalar&quot;\n  op: &quot;Const&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/Mul_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 2.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/scalar&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/Mul_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/sub&quot;\n  op: &quot;Sub&quot;\n  input: &quot;graphs/hot_at1/px/output/BiasAdd&quot;\n  input: &quot;x&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/Mul_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/mul&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/sub&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/mul_1&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Sum&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/mul_1&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Sum_1&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Neg&quot;\n  op: &quot;Neg&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Reshape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Neg&quot;\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Reshape&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Neg&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Neg&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/pz/zv/MatMul_grad/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;gradients/graphs/hot_at1/pz/zv/BiasAdd_grad/tuple/control_dependency&quot;\n  input: &quot;pz/zv/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/pz/zv/MatMul_grad/MatMul_1&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at1/Add&quot;\n  input: &quot;gradients/graphs/hot_at1/pz/zv/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/pz/zv/MatMul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at1/pz/zv/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at1/pz/zv/MatMul_grad/MatMul_1&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/pz/zv/MatMul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/pz/zv/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at1/pz/zv/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/pz/zv/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/pz/zv/MatMul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/pz/zv/MatMul_grad/MatMul_1&quot;\n  input: &quot;^gradients/graphs/hot_at1/pz/zv/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/pz/zv/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_4&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/graphs/hot_at0/pz/zv/BiasAdd_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/graphs/hot_at1/pz/zv/BiasAdd_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/pz/zv/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/pz/zm/MatMul_grad/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;gradients/graphs/hot_at1/pz/zm/BiasAdd_grad/tuple/control_dependency&quot;\n  input: &quot;pz/zm/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/pz/zm/MatMul_grad/MatMul_1&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at1/Add&quot;\n  input: &quot;gradients/graphs/hot_at1/pz/zm/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/pz/zm/MatMul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at1/pz/zm/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at1/pz/zm/MatMul_grad/MatMul_1&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/pz/zm/MatMul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/pz/zm/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at1/pz/zm/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/pz/zm/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/pz/zm/MatMul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/pz/zm/MatMul_grad/MatMul_1&quot;\n  input: &quot;^gradients/graphs/hot_at1/pz/zm/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/pz/zm/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_5&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/graphs/hot_at0/pz/zm/BiasAdd_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/graphs/hot_at1/pz/zm/BiasAdd_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/pz/zm/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/layer1/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/qy/layer1/Relu_grad/ReluGrad&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/layer1/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/qy/layer1/Relu_grad/ReluGrad&quot;\n  input: &quot;^gradients/qy/layer1/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/qy/layer1/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/qy/layer1/Relu_grad/ReluGrad&quot;\n  input: &quot;^gradients/qy/layer1/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/qy/layer1/Relu_grad/ReluGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/layer1/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/qy/layer1/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/qy/layer1/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/qy/layer1/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/px/output/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/px/output/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/tuple/control_dependency&quot;\n  input: &quot;^gradients/graphs/hot_at0/px/output/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/px/output/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/tuple/control_dependency&quot;\n  input: &quot;^gradients/graphs/hot_at0/px/output/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/mean_squared_error/SquaredDifference_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/px/output/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/px/output/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/graphs/hot_at0/px/output/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/px/output/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/px/output/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/px/output/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/tuple/control_dependency&quot;\n  input: &quot;^gradients/graphs/hot_at1/px/output/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/px/output/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/tuple/control_dependency&quot;\n  input: &quot;^gradients/graphs/hot_at1/px/output/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/mean_squared_error/SquaredDifference_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/px/output/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/px/output/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/graphs/hot_at1/px/output/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/px/output/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_6&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/graphs/hot_at0/pz/zv/MatMul_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/graphs/hot_at1/pz/zv/MatMul_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/pz/zv/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_7&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/graphs/hot_at0/pz/zm/MatMul_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/graphs/hot_at1/pz/zm/MatMul_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/pz/zm/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/layer1/MatMul_grad/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;gradients/qy/layer1/BiasAdd_grad/tuple/control_dependency&quot;\n  input: &quot;qy/layer1/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/layer1/MatMul_grad/MatMul_1&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;x&quot;\n  input: &quot;gradients/qy/layer1/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/layer1/MatMul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/qy/layer1/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/qy/layer1/MatMul_grad/MatMul_1&quot;\n}\nnode {\n  name: &quot;gradients/qy/layer1/MatMul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/qy/layer1/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/qy/layer1/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/qy/layer1/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/qy/layer1/MatMul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/qy/layer1/MatMul_grad/MatMul_1&quot;\n  input: &quot;^gradients/qy/layer1/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/qy/layer1/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/px/output/MatMul_grad/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;gradients/graphs/hot_at0/px/output/BiasAdd_grad/tuple/control_dependency&quot;\n  input: &quot;px/output/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/px/output/MatMul_grad/MatMul_1&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at0/px/layer1/Relu&quot;\n  input: &quot;gradients/graphs/hot_at0/px/output/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/px/output/MatMul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at0/px/output/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at0/px/output/MatMul_grad/MatMul_1&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/px/output/MatMul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/px/output/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at0/px/output/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/px/output/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/px/output/MatMul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/px/output/MatMul_grad/MatMul_1&quot;\n  input: &quot;^gradients/graphs/hot_at0/px/output/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/px/output/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/px/output/MatMul_grad/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;gradients/graphs/hot_at1/px/output/BiasAdd_grad/tuple/control_dependency&quot;\n  input: &quot;px/output/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/px/output/MatMul_grad/MatMul_1&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at1/px/layer1/Relu&quot;\n  input: &quot;gradients/graphs/hot_at1/px/output/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/px/output/MatMul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at1/px/output/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at1/px/output/MatMul_grad/MatMul_1&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/px/output/MatMul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/px/output/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at1/px/output/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/px/output/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/px/output/MatMul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/px/output/MatMul_grad/MatMul_1&quot;\n  input: &quot;^gradients/graphs/hot_at1/px/output/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/px/output/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_8&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/graphs/hot_at0/px/output/BiasAdd_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/graphs/hot_at1/px/output/BiasAdd_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/px/output/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/px/layer1/Relu_grad/ReluGrad&quot;\n  op: &quot;ReluGrad&quot;\n  input: &quot;gradients/graphs/hot_at0/px/output/MatMul_grad/tuple/control_dependency&quot;\n  input: &quot;graphs/hot_at0/px/layer1/Relu&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/px/layer1/Relu_grad/ReluGrad&quot;\n  op: &quot;ReluGrad&quot;\n  input: &quot;gradients/graphs/hot_at1/px/output/MatMul_grad/tuple/control_dependency&quot;\n  input: &quot;graphs/hot_at1/px/layer1/Relu&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_9&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/graphs/hot_at0/px/output/MatMul_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/graphs/hot_at1/px/output/MatMul_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/px/output/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/px/layer1/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/graphs/hot_at0/px/layer1/Relu_grad/ReluGrad&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/px/layer1/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at0/px/layer1/Relu_grad/ReluGrad&quot;\n  input: &quot;^gradients/graphs/hot_at0/px/layer1/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/px/layer1/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/px/layer1/Relu_grad/ReluGrad&quot;\n  input: &quot;^gradients/graphs/hot_at0/px/layer1/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/px/layer1/Relu_grad/ReluGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/px/layer1/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/px/layer1/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/graphs/hot_at0/px/layer1/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/px/layer1/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/px/layer1/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/graphs/hot_at1/px/layer1/Relu_grad/ReluGrad&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/px/layer1/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at1/px/layer1/Relu_grad/ReluGrad&quot;\n  input: &quot;^gradients/graphs/hot_at1/px/layer1/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/px/layer1/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/px/layer1/Relu_grad/ReluGrad&quot;\n  input: &quot;^gradients/graphs/hot_at1/px/layer1/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/px/layer1/Relu_grad/ReluGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/px/layer1/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/px/layer1/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/graphs/hot_at1/px/layer1/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/px/layer1/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/px/layer1/MatMul_grad/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;gradients/graphs/hot_at0/px/layer1/BiasAdd_grad/tuple/control_dependency&quot;\n  input: &quot;px/layer1/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/px/layer1/MatMul_grad/MatMul_1&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at0/qz/z_sample&quot;\n  input: &quot;gradients/graphs/hot_at0/px/layer1/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/px/layer1/MatMul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at0/px/layer1/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at0/px/layer1/MatMul_grad/MatMul_1&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/px/layer1/MatMul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/px/layer1/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at0/px/layer1/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/px/layer1/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/px/layer1/MatMul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/px/layer1/MatMul_grad/MatMul_1&quot;\n  input: &quot;^gradients/graphs/hot_at0/px/layer1/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/px/layer1/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/px/layer1/MatMul_grad/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;gradients/graphs/hot_at1/px/layer1/BiasAdd_grad/tuple/control_dependency&quot;\n  input: &quot;px/layer1/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/px/layer1/MatMul_grad/MatMul_1&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at1/qz/z_sample&quot;\n  input: &quot;gradients/graphs/hot_at1/px/layer1/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/px/layer1/MatMul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at1/px/layer1/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at1/px/layer1/MatMul_grad/MatMul_1&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/px/layer1/MatMul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/px/layer1/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at1/px/layer1/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/px/layer1/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/px/layer1/MatMul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/px/layer1/MatMul_grad/MatMul_1&quot;\n  input: &quot;^gradients/graphs/hot_at1/px/layer1/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/px/layer1/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_10&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/graphs/hot_at0/px/layer1/BiasAdd_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/graphs/hot_at1/px/layer1/BiasAdd_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/px/layer1/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_11&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/loss/loss_at0/sub_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at0/sub_1_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/graphs/hot_at0/px/layer1/MatMul_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 3\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/sub_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_12&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/loss/loss_at1/sub_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/loss/loss_at1/sub_1_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/graphs/hot_at1/px/layer1/MatMul_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 3\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/sub_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_13&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/graphs/hot_at0/px/layer1/MatMul_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/graphs/hot_at1/px/layer1/MatMul_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/px/layer1/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at0/qz/z/random_normal/mul&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at0/qz/zm/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/Shape&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/AddN_11&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/Sum&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/AddN_11&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/Sum_1&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/z/random_normal_grad/Reshape&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/z/random_normal_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/Reshape&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/z/random_normal_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/z/random_normal_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/Reshape_1&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/z/random_normal_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/z/random_normal_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at1/qz/z/random_normal/mul&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at1/qz/zm/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/Shape&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/AddN_12&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/Sum&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/AddN_12&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/Sum_1&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/z/random_normal_grad/Reshape&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/z/random_normal_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/Reshape&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/z/random_normal_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/qz/z/random_normal_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/Reshape_1&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/z/random_normal_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/qz/z/random_normal_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at0/qz/z/random_normal/RandomStandardNormal&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at0/qz/z/Sqrt&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/Shape&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/tuple/control_dependency&quot;\n  input: &quot;graphs/hot_at0/qz/z/Sqrt&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/mul&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/Sum&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;graphs/hot_at0/qz/z/random_normal/RandomStandardNormal&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/mul_1&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/Sum_1&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/Reshape&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/Reshape&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/Reshape_1&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/Shape&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at1/qz/z/random_normal/RandomStandardNormal&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/Shape_1&quot;\n  op: &quot;Shape&quot;\n  input: &quot;graphs/hot_at1/qz/z/Sqrt&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;out_type&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/BroadcastGradientArgs&quot;\n  op: &quot;BroadcastGradientArgs&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/Shape&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/tuple/control_dependency&quot;\n  input: &quot;graphs/hot_at1/qz/z/Sqrt&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/Sum&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/mul&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/BroadcastGradientArgs&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/Reshape&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/Sum&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/Shape&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;graphs/hot_at1/qz/z/random_normal/RandomStandardNormal&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/Sum_1&quot;\n  op: &quot;Sum&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/mul_1&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/BroadcastGradientArgs:1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tidx&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n  attr {\n    key: &quot;keep_dims&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/Reshape_1&quot;\n  op: &quot;Reshape&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/Sum_1&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/Shape_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;Tshape&quot;\n    value {\n      type: DT_INT32\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/Reshape&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/Reshape_1&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/Reshape&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/Reshape&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/Reshape_1&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/z/Sqrt_grad/SqrtGrad&quot;\n  op: &quot;SqrtGrad&quot;\n  input: &quot;graphs/hot_at0/qz/z/Sqrt&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal/mul_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/z/Sqrt_grad/SqrtGrad&quot;\n  op: &quot;SqrtGrad&quot;\n  input: &quot;graphs/hot_at1/qz/z/Sqrt&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal/mul_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_14&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/loss/loss_at0/truediv_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at0/Log_1_grad/mul&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/Sqrt_grad/SqrtGrad&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 3\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/truediv_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/zv/Softplus_grad/SoftplusGrad&quot;\n  op: &quot;SoftplusGrad&quot;\n  input: &quot;gradients/AddN_14&quot;\n  input: &quot;graphs/hot_at0/qz/zv/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_15&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/loss/loss_at1/truediv_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/loss/loss_at1/Log_1_grad/mul&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/Sqrt_grad/SqrtGrad&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 3\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/truediv_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/zv/Softplus_grad/SoftplusGrad&quot;\n  op: &quot;SoftplusGrad&quot;\n  input: &quot;gradients/AddN_15&quot;\n  input: &quot;graphs/hot_at1/qz/zv/BiasAdd&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_16&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/loss/loss_at0/sub_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/z/random_normal_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/sub_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/zm/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/AddN_16&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/zm/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/AddN_16&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/zm/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/zm/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/AddN_16&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/zm/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at0/sub_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/zm/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/zm/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/zm/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/zm/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/zv/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/zv/Softplus_grad/SoftplusGrad&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/zv/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/zv/Softplus_grad/SoftplusGrad&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/zv/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/zv/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/zv/Softplus_grad/SoftplusGrad&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/zv/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/zv/Softplus_grad/SoftplusGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/zv/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/zv/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/zv/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/zv/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_17&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/loss/loss_at1/sub_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/z/random_normal_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/sub_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/zm/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/AddN_17&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/zm/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/AddN_17&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/zm/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/zm/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/AddN_17&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/zm/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/loss/loss_at1/sub_grad/Reshape_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/zm/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/zm/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/zm/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/qz/zm/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/zv/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/zv/Softplus_grad/SoftplusGrad&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/zv/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/zv/Softplus_grad/SoftplusGrad&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/zv/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/zv/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/zv/Softplus_grad/SoftplusGrad&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/zv/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/qz/zv/Softplus_grad/SoftplusGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/zv/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/zv/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/zv/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/qz/zv/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/zm/MatMul_grad/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/zm/BiasAdd_grad/tuple/control_dependency&quot;\n  input: &quot;qz/zm/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/zm/MatMul_grad/MatMul_1&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at0/qz/layer1/Relu&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/zm/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/zm/MatMul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/zm/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/zm/MatMul_grad/MatMul_1&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/zm/MatMul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/zm/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/zm/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/zm/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/zm/MatMul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/zm/MatMul_grad/MatMul_1&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/zm/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/zm/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/zv/MatMul_grad/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/zv/BiasAdd_grad/tuple/control_dependency&quot;\n  input: &quot;qz/zv/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/zv/MatMul_grad/MatMul_1&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at0/qz/layer1/Relu&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/zv/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/zv/MatMul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/zv/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/zv/MatMul_grad/MatMul_1&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/zv/MatMul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/zv/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/zv/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/zv/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/zv/MatMul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/zv/MatMul_grad/MatMul_1&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/zv/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/zv/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/zm/MatMul_grad/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/zm/BiasAdd_grad/tuple/control_dependency&quot;\n  input: &quot;qz/zm/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/zm/MatMul_grad/MatMul_1&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at1/qz/layer1/Relu&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/zm/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/zm/MatMul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/zm/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/zm/MatMul_grad/MatMul_1&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/zm/MatMul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/zm/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/zm/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/qz/zm/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/zm/MatMul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/zm/MatMul_grad/MatMul_1&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/zm/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/qz/zm/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_18&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/zm/BiasAdd_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/zm/BiasAdd_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/zm/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/zv/MatMul_grad/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/zv/BiasAdd_grad/tuple/control_dependency&quot;\n  input: &quot;qz/zv/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/zv/MatMul_grad/MatMul_1&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at1/qz/layer1/Relu&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/zv/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/zv/MatMul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/zv/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/zv/MatMul_grad/MatMul_1&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/zv/MatMul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/zv/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/zv/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/qz/zv/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/zv/MatMul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/zv/MatMul_grad/MatMul_1&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/zv/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/qz/zv/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_19&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/zv/BiasAdd_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/zv/BiasAdd_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/zv/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_20&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/zm/MatMul_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/zv/MatMul_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/zm/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/layer1/Relu_grad/ReluGrad&quot;\n  op: &quot;ReluGrad&quot;\n  input: &quot;gradients/AddN_20&quot;\n  input: &quot;graphs/hot_at0/qz/layer1/Relu&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_21&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/zm/MatMul_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/zm/MatMul_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/zm/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_22&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/zm/MatMul_grad/tuple/control_dependency&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/zv/MatMul_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/qz/zm/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/layer1/Relu_grad/ReluGrad&quot;\n  op: &quot;ReluGrad&quot;\n  input: &quot;gradients/AddN_22&quot;\n  input: &quot;graphs/hot_at1/qz/layer1/Relu&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_23&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/zv/MatMul_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/zv/MatMul_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/zv/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/layer1/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/layer1/Relu_grad/ReluGrad&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/layer1/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/layer1/Relu_grad/ReluGrad&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/layer1/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/layer1/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/layer1/Relu_grad/ReluGrad&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/layer1/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/layer1/Relu_grad/ReluGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/layer1/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/layer1/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/layer1/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/layer1/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/layer1/BiasAdd_grad/BiasAddGrad&quot;\n  op: &quot;BiasAddGrad&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/layer1/Relu_grad/ReluGrad&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;data_format&quot;\n    value {\n      s: &quot;NHWC&quot;\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/layer1/BiasAdd_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/layer1/Relu_grad/ReluGrad&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/layer1/BiasAdd_grad/BiasAddGrad&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/layer1/BiasAdd_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/layer1/Relu_grad/ReluGrad&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/layer1/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/qz/layer1/Relu_grad/ReluGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/layer1/BiasAdd_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/layer1/BiasAdd_grad/BiasAddGrad&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/layer1/BiasAdd_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/qz/layer1/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/layer1/MatMul_grad/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/layer1/BiasAdd_grad/tuple/control_dependency&quot;\n  input: &quot;qz/layer1/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/layer1/MatMul_grad/MatMul_1&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at0/qz/xy/concat&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/layer1/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/layer1/MatMul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/layer1/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/layer1/MatMul_grad/MatMul_1&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/layer1/MatMul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/layer1/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/layer1/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/layer1/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at0/qz/layer1/MatMul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/layer1/MatMul_grad/MatMul_1&quot;\n  input: &quot;^gradients/graphs/hot_at0/qz/layer1/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/layer1/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/layer1/MatMul_grad/MatMul&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/layer1/BiasAdd_grad/tuple/control_dependency&quot;\n  input: &quot;qz/layer1/weights/read&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/layer1/MatMul_grad/MatMul_1&quot;\n  op: &quot;MatMul&quot;\n  input: &quot;graphs/hot_at1/qz/xy/concat&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/layer1/BiasAdd_grad/tuple/control_dependency&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;transpose_a&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;transpose_b&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/layer1/MatMul_grad/tuple/group_deps&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/layer1/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/layer1/MatMul_grad/MatMul_1&quot;\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/layer1/MatMul_grad/tuple/control_dependency&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/layer1/MatMul_grad/MatMul&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/layer1/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/qz/layer1/MatMul_grad/MatMul&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/graphs/hot_at1/qz/layer1/MatMul_grad/tuple/control_dependency_1&quot;\n  op: &quot;Identity&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/layer1/MatMul_grad/MatMul_1&quot;\n  input: &quot;^gradients/graphs/hot_at1/qz/layer1/MatMul_grad/tuple/group_deps&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at1/qz/layer1/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_24&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/layer1/BiasAdd_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/layer1/BiasAdd_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/layer1/BiasAdd_grad/BiasAddGrad&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;gradients/AddN_25&quot;\n  op: &quot;AddN&quot;\n  input: &quot;gradients/graphs/hot_at0/qz/layer1/MatMul_grad/tuple/control_dependency_1&quot;\n  input: &quot;gradients/graphs/hot_at1/qz/layer1/MatMul_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;N&quot;\n    value {\n      i: 2\n    }\n  }\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@gradients/graphs/hot_at0/qz/layer1/MatMul_grad/MatMul_1&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;beta1_power/initial_value&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.8999999761581421\n      }\n    }\n  }\n}\nnode {\n  name: &quot;beta1_power&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;beta1_power/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;beta1_power&quot;\n  input: &quot;beta1_power/initial_value&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;beta1_power/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;beta1_power&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;beta2_power/initial_value&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.9990000128746033\n      }\n    }\n  }\n}\nnode {\n  name: &quot;beta2_power&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;beta2_power/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;beta2_power&quot;\n  input: &quot;beta2_power/initial_value&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;beta2_power/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;beta2_power&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/weights/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/weights/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/weights/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qy/layer1/weights/Adam&quot;\n  input: &quot;qy/layer1/weights/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/weights/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qy/layer1/weights/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/weights/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/weights/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/weights/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qy/layer1/weights/Adam_1&quot;\n  input: &quot;qy/layer1/weights/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/weights/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qy/layer1/weights/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/biases/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/biases/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/biases/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qy/layer1/biases/Adam&quot;\n  input: &quot;qy/layer1/biases/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/biases/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qy/layer1/biases/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/biases/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/biases/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/biases/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qy/layer1/biases/Adam_1&quot;\n  input: &quot;qy/layer1/biases/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qy/layer1/biases/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qy/layer1/biases/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/weights/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/weights/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/weights/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qy/logit/weights/Adam&quot;\n  input: &quot;qy/logit/weights/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/weights/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qy/logit/weights/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/weights/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/weights/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/weights/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qy/logit/weights/Adam_1&quot;\n  input: &quot;qy/logit/weights/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/weights/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qy/logit/weights/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/biases/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/biases/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/biases/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qy/logit/biases/Adam&quot;\n  input: &quot;qy/logit/biases/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/biases/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qy/logit/biases/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/biases/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/biases/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/biases/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qy/logit/biases/Adam_1&quot;\n  input: &quot;qy/logit/biases/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qy/logit/biases/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qy/logit/biases/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/weights/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 4\n          }\n          dim {\n            size: 4\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/weights/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 4\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/weights/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qz/layer1/weights/Adam&quot;\n  input: &quot;qz/layer1/weights/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/weights/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qz/layer1/weights/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/weights/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 4\n          }\n          dim {\n            size: 4\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/weights/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 4\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/weights/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qz/layer1/weights/Adam_1&quot;\n  input: &quot;qz/layer1/weights/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/weights/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qz/layer1/weights/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/biases/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 4\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/biases/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/biases/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qz/layer1/biases/Adam&quot;\n  input: &quot;qz/layer1/biases/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/biases/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qz/layer1/biases/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/biases/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 4\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/biases/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/biases/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qz/layer1/biases/Adam_1&quot;\n  input: &quot;qz/layer1/biases/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qz/layer1/biases/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qz/layer1/biases/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/weights/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 4\n          }\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/weights/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/weights/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qz/zm/weights/Adam&quot;\n  input: &quot;qz/zm/weights/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/weights/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qz/zm/weights/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/weights/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 4\n          }\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/weights/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/weights/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qz/zm/weights/Adam_1&quot;\n  input: &quot;qz/zm/weights/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/weights/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qz/zm/weights/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/biases/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/biases/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/biases/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qz/zm/biases/Adam&quot;\n  input: &quot;qz/zm/biases/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/biases/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qz/zm/biases/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/biases/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/biases/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/biases/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qz/zm/biases/Adam_1&quot;\n  input: &quot;qz/zm/biases/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qz/zm/biases/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qz/zm/biases/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/weights/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 4\n          }\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/weights/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/weights/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qz/zv/weights/Adam&quot;\n  input: &quot;qz/zv/weights/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/weights/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qz/zv/weights/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/weights/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 4\n          }\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/weights/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 4\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/weights/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qz/zv/weights/Adam_1&quot;\n  input: &quot;qz/zv/weights/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/weights/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qz/zv/weights/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/biases/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/biases/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/biases/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qz/zv/biases/Adam&quot;\n  input: &quot;qz/zv/biases/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/biases/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qz/zv/biases/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/biases/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/biases/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/biases/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;qz/zv/biases/Adam_1&quot;\n  input: &quot;qz/zv/biases/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;qz/zv/biases/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;qz/zv/biases/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/weights/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/weights/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/weights/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;pz/zm/weights/Adam&quot;\n  input: &quot;pz/zm/weights/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/weights/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;pz/zm/weights/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/weights/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/weights/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/weights/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;pz/zm/weights/Adam_1&quot;\n  input: &quot;pz/zm/weights/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/weights/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;pz/zm/weights/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/biases/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/biases/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/biases/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;pz/zm/biases/Adam&quot;\n  input: &quot;pz/zm/biases/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/biases/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;pz/zm/biases/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/biases/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/biases/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/biases/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;pz/zm/biases/Adam_1&quot;\n  input: &quot;pz/zm/biases/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;pz/zm/biases/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;pz/zm/biases/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/weights/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/weights/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/weights/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;pz/zv/weights/Adam&quot;\n  input: &quot;pz/zv/weights/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/weights/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;pz/zv/weights/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/weights/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/weights/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/weights/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;pz/zv/weights/Adam_1&quot;\n  input: &quot;pz/zv/weights/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/weights/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;pz/zv/weights/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/biases/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/biases/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/biases/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;pz/zv/biases/Adam&quot;\n  input: &quot;pz/zv/biases/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/biases/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;pz/zv/biases/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/biases/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/biases/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/biases/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;pz/zv/biases/Adam_1&quot;\n  input: &quot;pz/zv/biases/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;pz/zv/biases/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;pz/zv/biases/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/weights/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/weights/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/weights/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;px/layer1/weights/Adam&quot;\n  input: &quot;px/layer1/weights/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/weights/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;px/layer1/weights/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/weights/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/weights/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/weights/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;px/layer1/weights/Adam_1&quot;\n  input: &quot;px/layer1/weights/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/weights/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;px/layer1/weights/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/biases/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/biases/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/biases/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;px/layer1/biases/Adam&quot;\n  input: &quot;px/layer1/biases/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/biases/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;px/layer1/biases/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/biases/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/biases/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/biases/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;px/layer1/biases/Adam_1&quot;\n  input: &quot;px/layer1/biases/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;px/layer1/biases/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;px/layer1/biases/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/output/weights/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/output/weights/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;px/output/weights/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;px/output/weights/Adam&quot;\n  input: &quot;px/output/weights/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;px/output/weights/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;px/output/weights/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/output/weights/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/output/weights/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;px/output/weights/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;px/output/weights/Adam_1&quot;\n  input: &quot;px/output/weights/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;px/output/weights/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;px/output/weights/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/weights&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/output/biases/Adam/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/output/biases/Adam&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;px/output/biases/Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;px/output/biases/Adam&quot;\n  input: &quot;px/output/biases/Adam/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;px/output/biases/Adam/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;px/output/biases/Adam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/output/biases/Adam_1/Initializer/zeros&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: &quot;px/output/biases/Adam_1&quot;\n  op: &quot;VariableV2&quot;\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;container&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;shape&quot;\n    value {\n      shape {\n        dim {\n          size: 2\n        }\n      }\n    }\n  }\n  attr {\n    key: &quot;shared_name&quot;\n    value {\n      s: &quot;&quot;\n    }\n  }\n}\nnode {\n  name: &quot;px/output/biases/Adam_1/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;px/output/biases/Adam_1&quot;\n  input: &quot;px/output/biases/Adam_1/Initializer/zeros&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;px/output/biases/Adam_1/read&quot;\n  op: &quot;Identity&quot;\n  input: &quot;px/output/biases/Adam_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Adam/learning_rate&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0010000000474974513\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Adam/beta1&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.8999999761581421\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Adam/beta2&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.9990000128746033\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Adam/epsilon&quot;\n  op: &quot;Const&quot;\n  attr {\n    key: &quot;dtype&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;value&quot;\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 9.99999993922529e-09\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_qy/layer1/weights/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;qy/layer1/weights&quot;\n  input: &quot;qy/layer1/weights/Adam&quot;\n  input: &quot;qy/layer1/weights/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/qy/layer1/MatMul_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_qy/layer1/biases/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;qy/layer1/biases&quot;\n  input: &quot;qy/layer1/biases/Adam&quot;\n  input: &quot;qy/layer1/biases/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/qy/layer1/BiasAdd_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_qy/logit/weights/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;qy/logit/weights&quot;\n  input: &quot;qy/logit/weights/Adam&quot;\n  input: &quot;qy/logit/weights/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/qy/logit/MatMul_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_qy/logit/biases/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;qy/logit/biases&quot;\n  input: &quot;qy/logit/biases/Adam&quot;\n  input: &quot;qy/logit/biases/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/qy/logit/BiasAdd_grad/tuple/control_dependency_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qy/logit/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_qz/layer1/weights/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;qz/layer1/weights&quot;\n  input: &quot;qz/layer1/weights/Adam&quot;\n  input: &quot;qz/layer1/weights/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/AddN_25&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_qz/layer1/biases/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;qz/layer1/biases&quot;\n  input: &quot;qz/layer1/biases/Adam&quot;\n  input: &quot;qz/layer1/biases/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/AddN_24&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_qz/zm/weights/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;qz/zm/weights&quot;\n  input: &quot;qz/zm/weights/Adam&quot;\n  input: &quot;qz/zm/weights/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/AddN_21&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_qz/zm/biases/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;qz/zm/biases&quot;\n  input: &quot;qz/zm/biases/Adam&quot;\n  input: &quot;qz/zm/biases/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/AddN_18&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zm/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_qz/zv/weights/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;qz/zv/weights&quot;\n  input: &quot;qz/zv/weights/Adam&quot;\n  input: &quot;qz/zv/weights/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/AddN_23&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_qz/zv/biases/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;qz/zv/biases&quot;\n  input: &quot;qz/zv/biases/Adam&quot;\n  input: &quot;qz/zv/biases/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/AddN_19&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@qz/zv/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_pz/zm/weights/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;pz/zm/weights&quot;\n  input: &quot;pz/zm/weights/Adam&quot;\n  input: &quot;pz/zm/weights/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/AddN_7&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_pz/zm/biases/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;pz/zm/biases&quot;\n  input: &quot;pz/zm/biases/Adam&quot;\n  input: &quot;pz/zm/biases/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/AddN_5&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zm/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_pz/zv/weights/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;pz/zv/weights&quot;\n  input: &quot;pz/zv/weights/Adam&quot;\n  input: &quot;pz/zv/weights/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/AddN_6&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_pz/zv/biases/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;pz/zv/biases&quot;\n  input: &quot;pz/zv/biases/Adam&quot;\n  input: &quot;pz/zv/biases/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/AddN_4&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@pz/zv/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_px/layer1/weights/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;px/layer1/weights&quot;\n  input: &quot;px/layer1/weights/Adam&quot;\n  input: &quot;px/layer1/weights/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/AddN_13&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_px/layer1/biases/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;px/layer1/biases&quot;\n  input: &quot;px/layer1/biases/Adam&quot;\n  input: &quot;px/layer1/biases/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/AddN_10&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_px/output/weights/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;px/output/weights&quot;\n  input: &quot;px/output/weights/Adam&quot;\n  input: &quot;px/output/weights/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/AddN_9&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/weights&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/update_px/output/biases/ApplyAdam&quot;\n  op: &quot;ApplyAdam&quot;\n  input: &quot;px/output/biases&quot;\n  input: &quot;px/output/biases/Adam&quot;\n  input: &quot;px/output/biases/Adam_1&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/learning_rate&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;Adam/epsilon&quot;\n  input: &quot;gradients/AddN_8&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/output/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;use_nesterov&quot;\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: &quot;Adam/mul&quot;\n  op: &quot;Mul&quot;\n  input: &quot;beta1_power/read&quot;\n  input: &quot;Adam/beta1&quot;\n  input: &quot;^Adam/update_qy/layer1/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_qy/layer1/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_qy/logit/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_qy/logit/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_qz/layer1/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_qz/layer1/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_qz/zm/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_qz/zm/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_qz/zv/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_qz/zv/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_pz/zm/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_pz/zm/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_pz/zv/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_pz/zv/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_px/layer1/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_px/layer1/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_px/output/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_px/output/biases/ApplyAdam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Adam/Assign&quot;\n  op: &quot;Assign&quot;\n  input: &quot;beta1_power&quot;\n  input: &quot;Adam/mul&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;Adam/mul_1&quot;\n  op: &quot;Mul&quot;\n  input: &quot;beta2_power/read&quot;\n  input: &quot;Adam/beta2&quot;\n  input: &quot;^Adam/update_qy/layer1/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_qy/layer1/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_qy/logit/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_qy/logit/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_qz/layer1/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_qz/layer1/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_qz/zm/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_qz/zm/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_qz/zv/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_qz/zv/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_pz/zm/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_pz/zm/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_pz/zv/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_pz/zv/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_px/layer1/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_px/layer1/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_px/output/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_px/output/biases/ApplyAdam&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n}\nnode {\n  name: &quot;Adam/Assign_1&quot;\n  op: &quot;Assign&quot;\n  input: &quot;beta2_power&quot;\n  input: &quot;Adam/mul_1&quot;\n  attr {\n    key: &quot;T&quot;\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: &quot;_class&quot;\n    value {\n      list {\n        s: &quot;loc:@px/layer1/biases&quot;\n      }\n    }\n  }\n  attr {\n    key: &quot;use_locking&quot;\n    value {\n      b: false\n    }\n  }\n  attr {\n    key: &quot;validate_shape&quot;\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: &quot;Adam&quot;\n  op: &quot;NoOp&quot;\n  input: &quot;^Adam/update_qy/layer1/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_qy/layer1/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_qy/logit/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_qy/logit/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_qz/layer1/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_qz/layer1/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_qz/zm/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_qz/zm/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_qz/zv/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_qz/zv/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_pz/zm/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_pz/zm/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_pz/zv/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_pz/zv/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_px/layer1/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_px/layer1/biases/ApplyAdam&quot;\n  input: &quot;^Adam/update_px/output/weights/ApplyAdam&quot;\n  input: &quot;^Adam/update_px/output/biases/ApplyAdam&quot;\n  input: &quot;^Adam/Assign&quot;\n  input: &quot;^Adam/Assign_1&quot;\n}\n';
          }
        </script>
        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>
        <div style=&quot;height:600px&quot;>
          <tf-graph-basic id=&quot;graph0.7386200175471126&quot;></tf-graph-basic>
        </div>
    "></iframe>
     </body> </html>